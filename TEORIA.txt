NODEMON ES MÁS PARA DESARROLLO

Y FOREVER Y PM2 SIRVEN MÁS PARA PRODUCCION

CLUSTER:
el modulo CLUSTER es nativo de Nodejs. no hace falta instalarlo, solo se importa en la aplicacion

el cluster sirve para crear procesos hijos

lo que hace es clonar el worker maestro y delegarle la carga de trabajo a cada uno de ellos, 
asi se evita la sobrecarga sobre un solo nucleo del procesador

sirve para utilizar todos los nucleos del procesador que estemos usando

primero se usa un if para ver si el proceso es el proceso maestro asi:
cluster.isPrimary (antes era isMaster pero lo cambiaron)

el codigo es igual para todos lso procesos, por eso hay que diferenciar si estamos en el maestro o no

PARA CREAR LOS PROCESOS hijos

if (cluster.isMaster) {
    console.log(`Master ${process.pid} is running`)

    for (let i = 0; i < numCPUs; i++)  {

    cluster.fork();
    }

    cluster.on('exit', (worker, code, signal) => {
        console.log(`Worker ${worker.process.pid} died`);
    })
}

el cluster.fork() crea el proceso
se lo llama tantas veces como nucleos de procesador yo tengo
esto crea una replica del proceso

si uno de los procesos hijos muere tenemos que recibir un evento 'exit'
y en base a eso podemos hacer el console.log como arriba
o crear uno nuevo para siempre tener un num determinado de hijos

la parte del else:
si estamos en el proceso hijo solo hay que poner a escuchar el servidor
ya que esto estariamos en el index.js

SERVER.js
aca van los endpoints

import express from 'express'
const app = express();

app.get('/', (req, res) => {
    res.json({
        pid: process.pid,
        msg: 'HOLA'
    });
});

para ver que proceso nos esta contestando es el get

y un endpoint en el que lo exigimos y que tarda tiempo en contestar:

app.get('/slow', (req, res) => {
    let sum = 0;
    for (let i = 0; i < 6e9; i++) {
        sum +=1;
        for (let i = 0; i < 6e9; i++) {
        }
        res.json({
            pid: process.pid,
            sum
        })
    }
})

y un endpoint para mostrar del otro lado cuando se muere un proceso:

app.get('/muerte', (req,res) => {
    res.json({msg: 'OK'});
    console.log(`PID => ${process.pid} will die`);
    process.exit(0);
})

export default app;

VENTAJA DE CLUSTER:
solo tenemos que modificar nuestro index para poner lo del index en nuestros procesos hijos
eso va en el ELSE del if (cluster.isPrimary)
esto es receta de cocina

FOREVER:
es como un nodemon que va corriendo el servidor cuando hacemos un cambio
pero hace una cosa mas:

es un modulo que nos permite correr nuestra app en segundo plano, 
lo cual nos permite presindir de la ventana de la terminal

y tambien:
a forever le podemos decir q si nuestra app se muere q la reinicie

instalar libreria: pero de forma global

npm i forever -g

eso significa q la podemos llamar de cualquier parte de nuestra computadora

luego se inicializa asi: (en vez de npm run dev)
"forever start dist/index.js"

como se q mi app esta corriendo?
agarramos cualquier terminal:

forever list

y vemos los procesos q estan activos

esto no tiene cluster, es solo un proceso

si lo mato forever la revive, asi que ahora es un nuevo ID de proceso

es instalar la aplicacion
levantarla con forever start 
despues con forever list vemos los procesos funcionando

con forever --help vemos los comandos que tenemos
uno importante es forever logs, o forever stop

ya veremos que con forever vamos a usar un script para iniciar produccion:

"prod": "npm run build && forever start dist/index.js",
"stop:all": "npm forever stopall"

con npm run prod levantamos forever
esto levanta al aplicacion ya podemos entrar a localhost

el stopall mata todos los procesos, si hacemos forever list no aparece ninguno
y no estaria ya nuestra aplicacion online en localhost

forever nos permite correr la aplicacion sin necesidad de una terminal
y su otra funcion es revivir el servidor cuando se muere
(pero no tiene cluster)

--------------------------------------------------

CLASE CLUSTERS HORA 1.00 EXPLICA COMO PASAR PUERTOS POR PARAMETRO
SE SACA LA BASE DE MINIMIST DE LA CLASE ANTERIOR

SE HACE CON MINIMIST, SE INSTALA LA LIBRERIA SE IMPORTA Y TIENE UNA funcion
donde le pasamos los alias "p": "puerto"
y los default 
dsp se hace forever start dist/index.js --puerto=8081   

ej:

import server from './services/server';
import minimist from 'minimist';

const argsObject = {
    alias: {
        p: 'puerto'
    },
    default: {
        puerto: '8080'
    }
};

const args = minimist(process.argv, argsObject)

const PORT = args.puerto;

server.listen(PORT, () => {
    console.log(`server ON escuchando en puerto ${PORT} - PID WORKER ${process.pid}`)
})



---------------------------------------------------

PM2:

hace una fusion entre FOREVER y CLUSTERS

cumple las mismas funciones de forever de:
- levantar el servidor cuando muere,
- correr en segundo plano sin necesidad de consola,
- hace toda la movida del clustering como hicimos en el ejercicio de 01-cluster
pero lo hace solo PM2 eso

npm i pm2 -g

para iniciar la ejecucion:

pm2 start dist/index.js 

a esto le podemos pasar argumentos como:

--name="serverUno" 

--watch 
el watch es como modo nodemon que cuando se detecte un cambio actualice

para ver todos nuestros procesos:

pm2 list

para ver detalles de un proceso se busca por orden tipo array de los ID asi:

pm2 describe 0 (nos da descripcion del primero de los procesos)

para frenar proceso:

pm2 stop 0

MODO CLUSTER
(tiene que haber de antemano un script de cluster:
"prod:fork": "npm run build && start dist/index.js --watch --name="ejemploPM2Fork")
"prod:cluster": "npm run build && start dist/index.js --watch -i max --name="ejemploPM2cluster")
el -i es el numero de clusters
el max sabe cuantos nucleos tenemos y crea un cluster para cada nucleo


pm2 start dist/index.js --name="ejemplo1" --watch -i 3

para ver todo con detalle los procesos:
pm2 monit

PM2 nos permite crear en la carpeta a nivel package.json un archivo: 
ecosystem.config.js (nombre del archivo)
donde ira una configuracion:

 module.exports = {
    apps: [
        {
            script: 'dist/index.js',
            watch: true,
            autorestart: true,
            instances: 3 (puede ser instances: max y usa el maximo de nucleos que tiene mi procesador)
        },
    ],
 };

 esto no hace falta hacerlo a mano, poniendo el comando:
 pm2 init simple
 ya genera el archivo, y ese lo modificamos con lo de arriba

y despues en el package.json iria el comando asi:

"start": "node dist/index.js",
"start:prod": "pm2 start ecosystem.config.js"

----------------------------------------------------------------------------

PROXY

es un servidor extra que ira de intermediario entre nustro cliente y servidor
tiene ventajas como:
-evitar que la conexion entre cliente-servidor sea directa, y esto lo hace mas seguro xq nadie conoce la direccion exacta de nuestro servidor, no se conoce IP 
-si hay q cambiar nuestro servidor de backend facilita todo
- al tener el intermediario podemos sumar funciones como:
    control de acceso: tipo filtro/firewall de ciertos clientes, podemos permitir q solo ciertos clientes peudan entrar,
    monitoreo y registro del trafico: el registro lo hace el servidor proxy, podemos ver quien hizo las peticiones, 
    podemos hacer un balanceo de carga, si entra mucha gente podemos crear muchos servidores replicas y al tener el proxy adelante todos le pegan a este y el proxy redirige las solicitudes a los dif servidores
-potente caching: podemos ligar un cacheo al servidor proxy, si llega una request y ya esta en cache ni siquiera pasa por el backend ya que se le responde antes con lo q estaba guardado
-compresion: a la respuesta comprimirla para que viaje menos data y llege mas rapido,
- cifrado SSL: para establecer una conexion segura entre el cliente y el servidor. Muy importante y es mas para produccion.

2 tipos de proxy:
SEGUN DE QUE LADO DE LA NUBE DE INTERNET SE ENCUENTREN:

DIRECTOS O FORWARD PROXY:
Es mas para el dia a dia, se coloca entre el clente y la INTERNET
esto se utiliza para ocultar la IP y mejorar la privacidad,
y evadir limitaciones por la geografia q tengamos 
(x ej si tenemos IP argentina y entramos a netflix hay ciertas peliculas q aca no se estrenaron x copyright en latinoamerica por ejemplo)



INVERSOS O REVERSE PROXY:
Sirve para actualizar la app de backend, es el que vamos a utilizar
procesa las solicitudes del cliente llevandolas al servidor backend, distribuyendo la carga entre varios servidores
en el servidor podemos crear replicas de servidores para agilizar la aplicacion
el proxy crea estos servidores replicas



------------------------------

NGINX

es un servidor web, le hace la contra al servidor Apache
actua como un proxy q vamos a configurar y decirle que hacer

utilizando NGINX creariamos un servidor que vamos a escuchar en puerto 80 si es HTTP (80 es el por defecto de HTTP)
y en puerto 443 HTTPS (puerto por defecto de HTTPS)

PARA INSTALAR NGINX
se descarga un .rar de la pagina nginx.org (la version estable)

lo descomprimimos en una carpeta en Disco Local C:



GUIA INSTALACION EN WINDOWS: 
HOW TO INSTALL NGINX WEBSERVER ON WINDOWS 10/8/7

minuto 0.29 clase proxy:
explica comandos para windows para operar con nginx
hay que posicionarnos en la carpeta donde estamos

y poner:

 ./nginx.exe -s reload

esto se usa mucho para cuando hacemos un cambio recargamos con esto el servidor

IMPORTANTE DESPUES DE HACER CADA COSA HACER EL 

./NGIX.EXE -S RELOAD

la movida de nginex se crean archuvos con extension .conf
y dentro de esas .conf va una base siempre asi:
----------------------------------------------------------
events {

}

http {
    server {
        listen: 80;
        server_name nginx-handbook.test;

        return 200 "hello from port 80!\n"
    }
        server {
        listen: 8080;
        server_name nginx-handbook.test;

        return 200 "hello from port 8080!\n"
    }
}

-----------------------------------------------------------

podemos crear varios servidores asi temporales y lo que pongamos dentro de server {}
va a ser la configuracion de ese servidor


PARA CREAR UNA CARPETA TIPO ESTÁTICA DONDE VA A IR TODO LO DE FRONT

EN LA CARPETA QUE DESCOMPRIMIMOS DE NGINX:
ESTA DENTRO DE LA CARPETA HTML TODO

Y EN EL CODIGO PONEMOS ROOT HTML
DENTRO DE HTTP{

}

----------------------------------------

PARA DEFINIR RUTAS CON NGINX:

DENTRO DE 
HTTP {
    SERVER {
        LISTEN 80;
        SERVER_NAME NGINX-HANDBOOK.TEST;

        LOCATION /INICIO {
            RETURN 200 "ESTA ES LA RUTA DE INICIO"

        }
            (cuando ponemos de esta forma todo lo que empieza con /inicio
            va a mostrar ese mensaje
            puede ser un /inicio-algomas
            y va a seguir mostrando eso)

        LOCATION = /IGUALACION {
            RETURN "DEVUELVO A IGUALACION
        }
            (cuando ponemos el = antes, buscamos un match exacto de la ruta)


        LOCATION ~ /REGULAR[0-9] {
            RETURN 200 "LOCATION CON EXPRESION REGULAR"
        }
            ( esto hace que podamos poner cualqueir numero luegode la / )

        LOCATION ~* /MAYUSCULA[0-9] {
            RETURN 200 "DEVUELVO CON MAYUSCULA.\n"

            ( lo mismo que el anterior pero con el * se vuelve case sensitive la ruta
            gralmente queremos que distinga las mayusculas en las rutas )
        }
    }
}

---------------------------------------------

Para crear varios servidores a la vez con NGINX:

events {

}

http {
    server {
        listen 80;
        server_name ngnix-handbook.text

        return 200 "hello from port 80 \n"
    }

    server {
        listen 8080;
        server_name ngnix-handbook.text

        return 200 "hello from port 8080 \n"
    }
}


-------------------------------------------------------------

PARA INCORPORAR un HTML Y CSS al servidor:
hay que mandarle donde esta la ruta de nuestros archivos estaticos
se hace poniendo dentro de:

http {

    types {
        text/html html;
        text/css css;
    }

    server {
        listen 80;

        root /var/www/html; 
    }
}

lo que esta dentro de types significa:
los archivos que terminen en html, que proxy los trate como html
los archivos que terminen en css, que proxy los trate como css
si no ponemos esto y hacemos los archivos, no los va a tomar



y lo que esta en root es la carpeta donde vamos a poner los archivos

----------------------------------------------------

otra forma facil de decirle que types de archivos vamos a usar
es importar el mime.types
es un archivo q esta donde instalamos todo
y tiene todos los tipos de archivos segun como terminan ya armados

para importar es asi:

http {
    include     mime.types;

    server {
        listen 80;
        server_name localhost;
    }
}


IMPORTANTE TERMINAR CADA SENTENCIA/RENGLON CON UN PUNTO Y COMA ;

EN WINDOWS USAMOS ROOT HTML (LLEVA A LA CARPETA DONDE INSTALAMOS TODO)

en esa carpeta podemos poner fotos, gifs, archivos html/css/js

----------------------

VARIABLES EN NGINX:

events {

}

http {
    
    server {
        
        listen 80;
        server_name localhost;

        location = /variables {
            return 200 " Host - $host\nURI - $uri\nARGS - $args"
        }
    }
}

los $host - $args - $URI 
SON VARIABLES PREDETERMINADAS DE NGINX Y MUESTRAN X EJEMPLO ESOS DATOS CUANDO LAS LLAMAMOS
SE PUEDEN ENCONTRAR EN:
HTTPS://NGINX.ORG/EN/DOCS/VARINDEX.HTML


-----------------------------------------------------

TRY FILES

es una forma de decirle a NGINX como tiene que trabajar en la resolucion

si tenemos archivos estaticos + endpoints
como sabemos si lo q pedimos es un archivo o un endpoint
x ej si /css/estilos.css es un archivo o un endpoint

entonces le decimos como tiene q trabajar

server {
    listen 80;
    server_name localhost;

    root /var/www/html;  -> aca vemos en la carpeta estatica si existen los archivos

                            si no existe lo buscamos como si fuese una ruta de location /

                            queda asi:

    try_files $uri $uri/ /not_found;    

                            si no existe, ejecutate la ruta /not_found

    location /not_found {
        return 404 "sadly, you've hit a brick wall \n"
    }


}

--------------------------

PROXY INVERSO
sirve para poner location / {
    
}
y eso significa que todo lo que pongamos como endpoint , es como un *
lo mande a tal puerto o haga tal cosa

events {

}

http {

    include mime.types

    server {
        listen 80;
        server_name ngnix.test
        
        location /ejemplo1 {
            proxy_pass "http://nginx.org/ 
        }
    }
}

-------------------------------------------------------

BALANCEADOR DE CARGA

events {

}

http {

    upstream mibackend {
        server localhost:3001;
        server localhost:3002;
    }

    server {
        listen 80
        server_name nginx-handbook.test;

        location / {
            proxy_pass http://mibackend;
        }
    }
}

IMPORTANTE

A ESTO HAY QUE SUMARLE EL ecosystem.config.js
algo asi por cada servidor:

module.exports = {
    apps [

{
    name: 'app1',
    script: 'dist/index.js',
    watch: true,
    autorestart: true;
    args: '--puerto=3001'
},
{
    name: 'app2',
    script: 'dist/index.js',
    watch: true,
    autorestart: true;
    args: '--puerto=3002'
},
{
    name: 'app3',
    script: 'dist/index.js',
    watch: true,
    autorestart: true,

    instances: 'max',

    args: '--puerto=3002'

}


{
    script: './service-worker',
    watch: ['./service-worker']
    },
    ]
}



para que corra en modo FORK 
no se le pasan en la config:

instances: 'max'

si le pasamos esa instancia, va a correr en modo CLUSTER
que significa que reparta el servidor entre todos los nucleos que tiene mi PROCESOS

EN ESTE CASO LA APP3 CORRE EN MODO CLUSTER, Y LAS PRIMERAS 2 EN MODO FORK
tambien se puede poner un numero que no sea 'max' en instances

-------------------------

la idea es crear una aplicacion q se va a dividir en 2
son 2 aplicaciones iguales que se escuchan en puertos distintos
como que lo estamos duplicando

y NGINX empieza a repartir equitativamente entre estos 2 servidores

SIRVE PARA QUE SE REPARTA EN PARTES IGUALES CADA ENTRADA DE UN CLIENTE AL servidor
si ponemos los 2 puertos como arriba
y recargamos la pagina, va a mandarnos una vez a cada puerto de esos 2

esto lo hace NGINX

el codigo uno solo
pero gracias a q le podemos pasar por argumento q puerto queremos escuchar 

al nginx le llegan las solicitudes y sabe q tiene esos 2 y los va repartiendo

----------------------------------------------------------

PARA HACER UNA GRAN APP BALANCEADA ES IMPORTANTE:

USAR EL MODO CLUSTER PONIENDO INSTANCES: 'MAX'

Y A ESO SE SUMA:

PONER EN HTTP {
    UPSTREAM MIBACKEND {
        SERVER LOCALHOST:3001;
        SERVER LOCALHOST:3002;
        SERVER LOCALHOST:3003;
    }
}

AHI TENEMOS 3 SERVIDORES AL MISMO TIEMPO FUNCIONANDO CON EL MISMO CODIGO
Y A ESO SE LE SUMA QUE SE REPARTE ENTRE LOS NUCLEOS DE LA PROCESOS

---------------------------------------------------

Para el desafio

agregar un parametro mas a la ruta del comando
q permita ejecutar en modo cluster o modo fork

es como el ejemplo de loadbalancer
pero nosotros estamos usando minimist 

la onda es que si ponemos en modo FORK arranque como siempre
pero si ponemos en argumento modo CLUSTER la idea es que hagamos por codigo la ejecucion del cluster

eso esta en 29-cluster -> 01-cluster 

donde creamos los hilos y cuando uno muere crea el otro
es lo de:

---------------------------------------------------------

import cluster from 'cluster';
import os from 'os';
import server from './services/server';

const numCPUs = os.cpus().length

const modoCluster = (aca armar el codigo para ver si recibi el argumento --modo=cluster)

 if (cluster.isMaster) {
    for (let i = 0; i < numCPUs; i++) {
        cluster.fork();
    }

    cluster.on('exit', (worker, code) => {
        cluster.fork();
    })
} else {
    const PORT = 8080;

    server.listen(PORT, () => {
        console.log('Servidor express escuchando en puerto')
    })
}


-------------

despues habria que poner para iniciar el servidor asi:

node dist/index.js --modo=fork

o

node dist/index.js --modo=cluster

usar minimist

------------------------------

CONSIGNA 2

ES SUMANDO A ESTO EJECUTARLO CON FOREVER
Y PROBARLO CON PM2

-------------------------

CONSIGNA 3 NGINX

la misma app que tenemos, la levantamos en el puerto 8081
despues en el archivo de configuracion: 
nginx.conf
todo lo que vaya a 

location /api/randoms {
    proxy_pass http://localhost:8081;
}

location / {
    proxy_pass http://localhost:8080;
}

luego:

en el ecosystem.config.js

en los args:    '--puerto=8080'
y               '--puerto=8081'

Y LUEGO:

PARA CORRERLO EN 8081, 8082, 8083, 8084

se pone en:

http {
    upstream mibackend {
        server localhost: 8081;
        server localhost: 8082;
        server localhost: 8083;
        server localhost: 8084;

    }

    server {
        listen 80;
        server name localhost;

        location / {
            proxy_pass http://mibackend;
        }
    }
}


-------------------------------------------------------------

TECNICAS PARA NO BARDEAR EN PRODUCCION CUANDO HAY MUCHOS clientes

EN EL CODIGO:

COMPRESION

SE COMPRIME EN UN GZIP
SE REDUCE EL TAMAÑO DEL CUERPO DE RESPUESTA Y AUMENTA LA VELOCIDAD DE LA APP
USAMOS GZIP, UN MIDDLEWARE DE COMPRESION DE NODE PARA APLICACIONES express

SI TENEMOS UN TRAFICO ELEVADO EN PRODUCCION NO ES LA MEJOR OPCION

SOLO HAY QUE IMPORTAR 

import express from 'express';
import compression from 'compression';

const app = express();

app.use(compression())

--------------------------------------------

si probamos esto en local no se mostraria la rapidez ,
hay que probarlo en produccion por ejemplo con GLITCH

y ahi es donde tarda en llegar al info de un servidor

------------------------------------------

IMPORTANTE SIEMPRE EN NODEJS - PARA MEJORAR EL RENDIMIENTO


- NO UTILIZAR FUNCIONES SINCRONICAS
TRATAR DE UTILIZAR TODO CON FUNCIONES ASINCRONICAS QUE ES LA CLAVE DE NODEJS

-EVITAR SU USO EN PRODUCCION

LA UNICA VEZ QUE SE PUEDE USAR LA FUNCION SINCRONICA ES EN EL ARRANQUE INICIAL 
OSEA EN EL INDEX.js

EN .ENV PONER:

NODE_ENV=PRODUCTION

ESTO HACE QUE EXPRESS "SE PONGA LAS PILAS" Y PUEDE FUNCIONAR HASTA 3 VECES MAS RAPIDO 

-----------------------------------------------

REALIZAR UN REGISTRO CORRECTO

ACA ENTRAN LOS CONSOLE.LOG() O CONSOLE.ERR()  QUE SON COMUNES EN DESARROLLO
PERO EN PRODUCCION NO SIRVEN PORQUE SON SINCRONICAS

PARA PRODUCCION:
- VAMOS A USAR LA LIBRERIA DE DEBUG
QUE SIRVE PARA DEPURACION

- Y PARA REGISTRAR LA ACTIVIDAD DE LA APLICACION,
QUE EN VEZ DE USAR CONSOLE.LOG(),
VAMOS A USAR BIBLIOTECAS DE REGISTRO COMO 
WINSTON O BUNYAN

---------------------------------------------

MANEJAR LAS EXCEPCIONES CORRECTAMENTE

las aplicaciones Node se bloquean cuando encuentran una excepcion no capturada
si no manejamos las excepciones la aplicacion Express se bloquea y queda fuera del intermediario

si nos aseguramos de que la aplicacion se reinicie automaticamente mas abajo,
esta se recupera de un bloqueo

PARA ESTO SE UTILIZA TRY / CATCH 
Y PROMISES

-------------------------------------------------

CAMBIOS EN EL ENTORNO QUE PODEMOS HACER (EN VEZ DEL CODIGO QUE ES LO DE ARRIBA)

- CREAR UNA VARIABLE DE ENTORNO NODE_ENV Y PONERLA COMO PRODUCTION
ASI HACEMOS QUE EXPRESS MISMO SE COMPORTE EN MODO PRODUCCION Y MEJORA SU RENDIMIENTO

ESTO LO HACEMOS DESDE LA TERMINAL O USANDO DOTENV CREANDO EN NUESTRO .NODE_ENV
Y LO METEMOS HAI JUNTO CON EL STRING DE CONEXION Y PUERTOS


ES IMPORTANTE:

- HACER QUE LA APP SE REINICIE automaticamente
USANDO FOREVER O PM2 LOGRAMOS QUE SI MUERE HAYA ALGO QUE LA REINICIE automaticamente
ES CLAVE PARA QUE SIEMPRE ESTE VIVE


IDEAL ES USAR PM2

- EJECUTAR LA APP EN MODO CLUSTER 
(SISTEMA MULTINUCLEO PARA MULTIPLICAR EL RENDIMIENTO DE LA APLCIACION)
USANDO 1 PROCESO POR CADA NUCLEO QUE TENGAMOS
ACA TAMBIEN ENTRA PM2

SE INSTALA PM2
SE CONFIGURA 
Y SE PONEN LOS INSTANCES: 'MAX'

Y LISTO, NO ES NECESARIO TOCAR EL CODIGO 

- ALMACENAR LAS RESPUESTAS EN CACHE 
ESTO LIBERA AL BACKEND DE RESPONDER UNA Y OTRA VEZ LO MISMO


ACA PODEMOS USAR NGINX O TAMBIEN REDIS

- UTILIZAR UN BALANCEADOR DE CARGAS

ESTO ES NGINX
DONDE PONEMOS LA APP EN MODO CLUSTER
Y ADEMAS REPLICARLA EN VARIOS PUERTOS A LA VEZ QUE LUEGO VAN AL PROXY QUE LOS REPARTE
USANDO UN PROXY INVERSO ADELANTE MULTIPLICAMOS LA CAPACIDAD DE NUESTRA APLCIACION

LO IDEAL SIEMPRE ES USAR UN SERVIDOR EXPRESS CON UN PROXY INVERSO HECHO CON NGINX 

EL PROXY INVERSO SE COLOCA DELANTE DE UNA APLCIACION WEB Y REALIZA OPERACIONES DE SOPORTE EN LAS SOLICITUDES, ANTES DE DIRIGIR LAS SOLICITUDES A LA APLICACION 
PUEDE MANEJAR LAS PAGINAS DE ERORRES, LA COMPRESION,  EL ALMACENAMIENTO EN CACHE, EL SERVICIO DE ARCHIVOS Y EL EQUILIBRIO DE CARGA, ENTRE OTROS.





-----------------------------------------------------------------------------------------------------------------


LOS LOGS SON LOS REGISTROS DE LA ACTIVIDAD DE NUESTRA APP

INGRESANDO A LOS LOGS SABRIAMOS SI ESTA FUNCIONANDO O NO

SI NOS DICEN QUE NO FUNCIONA LA APP
ENTRAMOS A LOS LOGS PARA VERIFICAR DONDE ESTA EL ERROR
AHI ESTAN LAS PRUEBAS DE TODO

LA FORMA MAS FACIL ES PONER CONSOLE.LOG A TODO

LIBRERIA QUE HACE ESTO DE GUARDAR LOS LOGS CON HORA Y DIA:

log4js

SE INSTALA Y SE IMPORTA

luego dentro de alguna funcion ponemos

export const funcion1 = () => {
    const logger = log4js.getLogger();

    logger.level = 'warn';
}

tambien hay otras funciones como
logger.trace
logger.debug 
logger.info (si quiero que sea algo informativo) 
logger.warn (para avisar algo q valga la pena pero q la app sigue funcionando)
logger.error (para imprimir el error)
logger.fatal (para cuando la app murio)

estan en orden desde el menos importante al menos importante em lo que es el aviso
 
ENTONCES SI PONEMOS EL NUVEL DESDE EL QUE QUEREMOS IMPRMIR
LOGGER.LEVEL = 'WARN';
NOS IMPRIME LOS LOGS DESDE ESE NIVEL HACIA ARRIBA EN IMPORTANCIA, todos

PODEMOS DECIRNOS QUE MANDE LOS LOGS A UN ARCHIVO

----------------------

PARA IMPRIMIR NUESTROS LOGS EN UN ARCHIVO 
- USAMOS APPENDER, QUE DICE A DONDE VAMOS A MANDAR ESO 
- USAMOS CATEGORIES,  

export const funcion2 = () => {
    log4js.configure({
        appenders: {
            fileAppender: {type: 'file', filename: './logs/example-1.log'}
        }
        categories: {
            default: {appenders: ['fileAppender'], level: 'error'}
        }
    });

    const logger = log4js.getLogger();

    logger.level = 'warn';

}

en el appender creamos una salida que le ponemos como nombre fileAppender
que sera del tipo file
y sera ubicado en la carpeta /logs 
en el archivo example-1.logs
(osea, voy a crear una salida donde los logs vayan a un archivo, que es el filename: '')

para utilizar esta salida tenemos que configurar una categoria
en categories: 
creamos nuestros loggers
ahi le decimos que appenders tiene que utilizar

DONDE GUARDAR ESTOS ARCHIVOS : 
HAY PLATAFORMAS EN LA NUBE (CLOUDWATCH, DATALOG, HAY ALGUNOS GRATIS )

DATALOG:

ES UNA HERRAMIENTA MUY UTIL 

NOSOTROS LES PASAMOS NUESTROS LOGS 
Y NOS ARMA UNA METRICA DE LOS MOVIMIENTOS QUE HUBO 




O GUARDARLO EN EL MISMO SERVIDOR DE MI BACKEND
PERO HAY QUE TENER CUIDADO PORQUE SE VA A LLENAR ESE ARCHIVO
ENTONCES PODEMOS PONER QUE A LOS 15 DIAS BORRE LOS LOGS ANTERIORES, O ALGO ASI

----------------

LOGS EN ARCHIVO:

ES LO MISMO PERO ANTES DE LOS LOG HAY QUE PONER UN LOG4JS.CONFIGURE({ })

SI QUEREMOS SUMAR UN APPENDER SE PONE ASI:

    log4js.configure({
        appenders: {
            fileAppender: {type: 'file', filename: './logs/example-1.log'}
            consola: {type: 'console'}
        }
        categories: {
            default: {appenders: ['fileAppender', 'consola'], level: 'error'}
        }
    })

------------------

esto haria que se imprima en un archivo, y tambien en la consola

------------------------------------------------------------------------

YA CON ESTO PODRIAMOS IMPLEMENTARLO EN NUESTRAS APLICACIONES
Y EN VEZ DE PONER CONSOLE.LOG() EN LAS FUNCIONES
HAY QUE ACOSTUMBRARSE A PONER:
LOGER.WARN()
O LOGGER.INFO()


-------------------------------------------------------------------------------------

WINSTON (es como log4js)

ES UNA LIBRERIA QUE SOPORTA PARA MANDAR A ARCHIVOS, A CONSOLA, NUBE... SE BANCA TODO
A ESTO TAMBIEN SE LE DICE QUE TIENE SOPORTE PARA MULTIPLES TRANSPORTES DISEÑADA PARA EL REGISTRO

UN TRANSPORTE ES UN DISPOSITIVO QUE NOS PERMITE ALMACENAR MENSAJES EN UN ARCHIVO O CONSOLA

LA LOGICA ES PARECIDA A log4js, tiene nombres parecidos los logger.debug, logger.error, etc pero parecidos

LA DIFERENCIA ES QUE NOS MANDA LOS LOGS EN UN OBJETO
CADA LOG EN UN OBJETO
SON MEJORES PARA HACER BUSQUEDAS DESPUES


--------------------------------------------------------------------------------------

PINO 

ES COMO log4js y WINSTON

LO QUE TIENE DE BUENO ES QUE EN LOS
LOGGER.trace
LOGGER.FATAL 

PODEMOS PASARLE OBJETOS

export const ejemplo1 = () => {
    const logger = pino({ level: 'trace' })

    logger.trace({
    mensaje: 'Imprimimos trace',
    nombre: 'cristian',
    edad: 22
    });

}

---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------

PROFILING Y DEBUG

PARA QUE NOS SIRVE EL PROFILING?
HACE TESTS DE CARGA/ESTRES QUE SIMULA COMO SE VA A COMPORTAR NUESTRA APP EN PRODUCCION

ARTILLERY 

es una dependencia de Node que nos permite obtener informacion a nivel cuantitativo
sobre como se va a comprortar nuestra app en produccion
sirve para cuando las paginas van a recibir muchos clientes y prevenir problemas

nos da pruebas reales para darle a nuestro cliente

SE INSTALA ARTILLERY DE FORMA GLOBAL
NPM I ARTILLERY -g

 y en el package.json van:
 como en el ejercicio de cluster/fork
 "start:fork": "node dist/index.js --puerto=8081", (esto con el minimist armado en el index.js para pasar parametro de puerto)
 "start:cluster": node dist/index.js --puerto=8082 --cluster",

 "artillery:fork": "artillery quick --count 50 n- 40 http://localhost:8081/prime?max=100000",
 "artillery:cluster": "artillery quick --count 50 n- 40 http://localhost:8082/prime?max=100000",

el --count 50 simula que hay 50 clientes
el -n 40 simula que cada cliente hace 40 requests

este sería un test rapido "a lo bruto", le pegan todos juntos al mismo tiempo
-----------------------------------------------
luego ARTILLERY nos permite hacer una segmentacion

si tenemos corriendo fork y cluster en los puertos 8081 y 8082 al mismo tiempo

---------------------------------------

FORMATO .YML EN ARTYLLERY

ES UN FORMATO AMIGABLE, ES COMO UN OBJETO PERO SACA LAS LLAVES Y CORCHETES, COMAS...

UN ARCHIVO .YML ES COMO UN PUG

hay un JSON - YAML CONVERTER PARA VER QUE onda

LOS ARRAY SE PONEN ASI

HOBBIES:
-FUTBOL
-PLAY
-ASADO

en vez de:

{
    "hobbies": ["futbol", "play", "asado"]
}

LOS ARRAY DE OBJETOS ASI:

arrayCalificaciones:
-materia: ingles
 nota: 8
-materia: matematica
 nota: 8

 en vez de:
 {
    "calificaciones":  
    [
        {
            "materia": "ingles", "nota": 8
        },
        {
            "materia": "matematica", "nota": 8
        }
    ]
    
 }

------------------------------------------

EN ARTILLERY SE ESCRIBE UN ARCHIVO .YML CON TODA LA CONFIGURACION QUE VAMOS A USAR 

config:
    target: 'http://localhost:8081;

    phases:
        -duration: 5
        arrivalRate: 50 (50 clientes se van a crear cada 5 segundos)
        name: Warm up 
    payload:
        path: 'keys.csv'
        fields:
            - 'id 

    scenarios:
        -name: ''
        flow:
            - get: 
                url: '/api/materials'
            - think: 10
            - get:
                url: '/api/materials?id={{id}}'


eca lo que hace es pedir los materiales, esperar 10 segundos 
y luego pedir materiales por ID

en payload vamos a usar ciertas cosas que estan en otro archivo llamado:
keys.csv

ahi tenemos IDs que tenemos en nuestra base de datos,
entonces los agarra para el get by ID 

---------------------------------------------------

COSAS QUE HAY QUE HACER PARA TENER UN SERVIDOR BALANCEADO Y QUE SE BANQUE MUCHOS clientes

- MODO CLUSTER PARA QUE TRABAJE CON TODOS LOS NUCLEOS DE LA CPU 
- NGINX PARA QUE TRABAJEMOS EL MISMO SERVIDOR EN VARIOS PUERTOS A LA VEZ QUE PASAN POR EL NGINX AL FINAL Y ES TODO UN SERVIDOR 
- EVITAR CODIGO SINCRONICO SIEMPRE 
- EVITAR CONSOLE.LOGS, USAR LOS LOGGERS QUE RECONTRA VAN 


--------------------------------------------------------------------------

PROFILING

EL PROFILING ES UN ANALISIS DE RENDIMIENTO 
ANALIZAMOS CIERTAS PARTES DE CODIGO PARA DETECTAR POSIBLES CUELLOS DE BOTELLA

en el package.json hay que meter estos script:

"start:profiling": "node --prof --logfile=foo.log --no-logfile-per-isolate dist/index.js",
"start:inspect": "node --inspect dist/index.js"


CURL 

ES UN CLIENTE PARA REALIZAR PETICIONES HTTP DESDE LA TERMINAL 
SE UTILIZA MUCHO PARA EJECUTAR SCRIPTS 

PARA HERRAMIENTAS COMO AXIOS POR DEBAJO SE USA ALGO COMO ESTO 

NODEJS AXIOS NOS ESCRIBE EL CODIGO 

LA VERSION AXIOS NATIVA ESTA BUENA 

--------------

PARA ENCRIPTAR CONTRASEÑAS SE USA UNA LIBRERIA LLAMADA CRYPTO 

---------------------------------

CLAVES PARA PROFILING

SE HACE UN ARCHIVO CON CURL

ESTE TIENE SCRIPTS QUE SE EJECUTAN SOLOS COMO UN POSTMAN
CUANDO LE HACEMOS NODE /ARCHIVO
extension .sh 


X EJEMPLO CREA UN USUARIO (1 LINEA CURL)
Y PRUEBA 100 REQUESTS CON ARTILLERY

script para CURL : 

--------------------------------------------------

curl -X get "http://localhost:8080/newUser?username=gonzi&password=1234"

artillery quick --count 10 -n 50 "http://localhost:8080/autorizarUser?username=gonzi&password=1234" >     result_bloq.txt 

el > manda resultados a un archivo con ese nombre 

--------------------------------------------

Y HAY UNA FORMA DE EN VEZ DE MOSTRAR EN CONSOLA, Q MANDE A UN ARCHIVO EL ANALISIS 

QUEDAN LOS SCRIPTS ASI:

primero:
node --inspect /scritps/script1.sh
(puede ser asi:
"start:inspect": "node --inspect dist/index.js",
"start"profiling": "node --prof --logfile= foo.log --no-logfile-per-isolate dist/index.js")

el --prof crea un archivo nuevo 
(en este caso isolate-0x1241241-412-v8.log) 
en este archivo tenemos la info pa saber si nuestra app funciona bien o no

esto nos da un archivo feo hecho para q lea una maquina 

entonces tenemos que convertirlo asi:

node --prof-process [nombreArchivoIsolate].log > [archivoSalida].txt 

el > crea un archivo con el nombre q pongamos 

y en ese archivo nos tira cuanto tiempo estuvo el procesador haciendo ciertas cosas
lo + imp es la cant de procesador q le costo hacer cada trabajo (medido en pulsos -> ticks)


