NODEMON ES MÁS PARA DESARROLLO

Y FOREVER Y PM2 SIRVEN MÁS PARA PRODUCCION

CLUSTER:
el modulo CLUSTER es nativo de Nodejs. no hace falta instalarlo, solo se importa en la aplicacion

el cluster sirve para crear procesos hijos

lo que hace es clonar el worker maestro y delegarle la carga de trabajo a cada uno de ellos, 
asi se evita la sobrecarga sobre un solo nucleo del procesador

sirve para utilizar todos los nucleos del procesador que estemos usando

primero se usa un if para ver si el proceso es el proceso maestro asi:
cluster.isPrimary (antes era isMaster pero lo cambiaron)

el codigo es igual para todos lso procesos, por eso hay que diferenciar si estamos en el maestro o no

PARA CREAR LOS PROCESOS hijos

if (cluster.isMaster) {
    console.log(`Master ${process.pid} is running`)

    for (let i = 0; i < numCPUs; i++)  {

    cluster.fork();
    }

    cluster.on('exit', (worker, code, signal) => {
        console.log(`Worker ${worker.process.pid} died`);
    })
}

el cluster.fork() crea el proceso
se lo llama tantas veces como nucleos de procesador yo tengo
esto crea una replica del proceso

si uno de los procesos hijos muere tenemos que recibir un evento 'exit'
y en base a eso podemos hacer el console.log como arriba
o crear uno nuevo para siempre tener un num determinado de hijos

la parte del else:
si estamos en el proceso hijo solo hay que poner a escuchar el servidor
ya que esto estariamos en el index.js

SERVER.js
aca van los endpoints

import express from 'express'
const app = express();

app.get('/', (req, res) => {
    res.json({
        pid: process.pid,
        msg: 'HOLA'
    });
});

para ver que proceso nos esta contestando es el get

y un endpoint en el que lo exigimos y que tarda tiempo en contestar:

app.get('/slow', (req, res) => {
    let sum = 0;
    for (let i = 0; i < 6e9; i++) {
        sum +=1;
        for (let i = 0; i < 6e9; i++) {
        }
        res.json({
            pid: process.pid,
            sum
        })
    }
})

y un endpoint para mostrar del otro lado cuando se muere un proceso:

app.get('/muerte', (req,res) => {
    res.json({msg: 'OK'});
    console.log(`PID => ${process.pid} will die`);
    process.exit(0);
})

export default app;

VENTAJA DE CLUSTER:
solo tenemos que modificar nuestro index para poner lo del index en nuestros procesos hijos
eso va en el ELSE del if (cluster.isPrimary)
esto es receta de cocina

FOREVER:
es como un nodemon que va corriendo el servidor cuando hacemos un cambio
pero hace una cosa mas:

es un modulo que nos permite correr nuestra app en segundo plano, 
lo cual nos permite presindir de la ventana de la terminal

y tambien:
a forever le podemos decir q si nuestra app se muere q la reinicie

instalar libreria: pero de forma global

npm i forever -g

eso significa q la podemos llamar de cualquier parte de nuestra computadora

luego se inicializa asi: (en vez de npm run dev)
"forever start dist/index.js"

como se q mi app esta corriendo?
agarramos cualquier terminal:

forever list

y vemos los procesos q estan activos

esto no tiene cluster, es solo un proceso

si lo mato forever la revive, asi que ahora es un nuevo ID de proceso

es instalar la aplicacion
levantarla con forever start 
despues con forever list vemos los procesos funcionando

con forever --help vemos los comandos que tenemos
uno importante es forever logs, o forever stop

ya veremos que con forever vamos a usar un script para iniciar produccion:

"prod": "npm run build && forever start dist/index.js",
"stop:all": "npm forever stopall"

con npm run prod levantamos forever
esto levanta al aplicacion ya podemos entrar a localhost

el stopall mata todos los procesos, si hacemos forever list no aparece ninguno
y no estaria ya nuestra aplicacion online en localhost

forever nos permite correr la aplicacion sin necesidad de una terminal
y su otra funcion es revivir el servidor cuando se muere
(pero no tiene cluster)

--------------------------------------------------

CLASE CLUSTERS HORA 1.00 EXPLICA COMO PASAR PUERTOS POR PARAMETRO
SE SACA LA BASE DE MINIMIST DE LA CLASE ANTERIOR

SE HACE CON MINIMIST, SE INSTALA LA LIBRERIA SE IMPORTA Y TIENE UNA funcion
donde le pasamos los alias "p": "puerto"
y los default 
dsp se hace forever start dist/index.js --puerto=8081   

ej:

import server from './services/server';
import minimist from 'minimist';

const argsObject = {
    alias: {
        p: 'puerto'
    },
    default: {
        puerto: '8080'
    }
};

const args = minimist(process.argv, argsObject)

const PORT = args.puerto;

server.listen(PORT, () => {
    console.log(`server ON escuchando en puerto ${PORT} - PID WORKER ${process.pid}`)
})



---------------------------------------------------

PM2:

hace una fusion entre FOREVER y CLUSTERS

cumple las mismas funciones de forever de:
- levantar el servidor cuando muere,
- correr en segundo plano sin necesidad de consola,
- hace toda la movida del clustering como hicimos en el ejercicio de 01-cluster
pero lo hace solo PM2 eso

npm i pm2 -g

para iniciar la ejecucion:

pm2 start dist/index.js 

a esto le podemos pasar argumentos como:

--name="serverUno" 

--watch 
el watch es como modo nodemon que cuando se detecte un cambio actualice

para ver todos nuestros procesos:

pm2 list

para ver detalles de un proceso se busca por orden tipo array de los ID asi:

pm2 describe 0 (nos da descripcion del primero de los procesos)

para frenar proceso:

pm2 stop 0

MODO CLUSTER
(tiene que haber de antemano un script de cluster:
"prod:fork": "npm run build && start dist/index.js --watch --name="ejemploPM2Fork")
"prod:cluster": "npm run build && start dist/index.js --watch -i max --name="ejemploPM2cluster")
el -i es el numero de clusters
el max sabe cuantos nucleos tenemos y crea un cluster para cada nucleo


pm2 start dist/index.js --name="ejemplo1" --watch -i 3

para ver todo con detalle los procesos:
pm2 monit

PM2 nos permite crear en la carpeta a nivel package.json un archivo: 
ecosystem.config.js (nombre del archivo)
donde ira una configuracion:

 module.exports = {
    apps: [
        {
            script: 'dist/index.js',
            watch: true,
            autorestart: true,
            instances: 3 (puede ser instances: max y usa el maximo de nucleos que tiene mi procesador)
        },
    ],
 };

 esto no hace falta hacerlo a mano, poniendo el comando:
 pm2 init simple
 ya genera el archivo, y ese lo modificamos con lo de arriba

y despues en el package.json iria el comando asi:

"start": "node dist/index.js",
"start:prod": "pm2 start ecosystem.config.js"

----------------------------------------------------------------------------

PROXY

es un servidor extra que ira de intermediario entre nustro cliente y servidor
tiene ventajas como:
-evitar que la conexion entre cliente-servidor sea directa, y esto lo hace mas seguro xq nadie conoce la direccion exacta de nuestro servidor, no se conoce IP 
-si hay q cambiar nuestro servidor de backend facilita todo
- al tener el intermediario podemos sumar funciones como:
    control de acceso: tipo filtro/firewall de ciertos clientes, podemos permitir q solo ciertos clientes peudan entrar,
    monitoreo y registro del trafico: el registro lo hace el servidor proxy, podemos ver quien hizo las peticiones, 
    podemos hacer un balanceo de carga, si entra mucha gente podemos crear muchos servidores replicas y al tener el proxy adelante todos le pegan a este y el proxy redirige las solicitudes a los dif servidores
-potente caching: podemos ligar un cacheo al servidor proxy, si llega una request y ya esta en cache ni siquiera pasa por el backend ya que se le responde antes con lo q estaba guardado
-compresion: a la respuesta comprimirla para que viaje menos data y llege mas rapido,
- cifrado SSL: para establecer una conexion segura entre el cliente y el servidor. Muy importante y es mas para produccion.

2 tipos de proxy:
SEGUN DE QUE LADO DE LA NUBE DE INTERNET SE ENCUENTREN:

DIRECTOS O FORWARD PROXY:
Es mas para el dia a dia, se coloca entre el clente y la INTERNET
esto se utiliza para ocultar la IP y mejorar la privacidad,
y evadir limitaciones por la geografia q tengamos 
(x ej si tenemos IP argentina y entramos a netflix hay ciertas peliculas q aca no se estrenaron x copyright en latinoamerica por ejemplo)



INVERSOS O REVERSE PROXY:
Sirve para actualizar la app de backend, es el que vamos a utilizar
procesa las solicitudes del cliente llevandolas al servidor backend, distribuyendo la carga entre varios servidores
en el servidor podemos crear replicas de servidores para agilizar la aplicacion
el proxy crea estos servidores replicas



------------------------------

NGINX

es un servidor web, le hace la contra al servidor Apache
actua como un proxy q vamos a configurar y decirle que hacer

utilizando NGINX creariamos un servidor que vamos a escuchar en puerto 80 si es HTTP (80 es el por defecto de HTTP)
y en puerto 443 HTTPS (puerto por defecto de HTTPS)

PARA INSTALAR NGINX
se descarga un .rar de la pagina nginx.org (la version estable)

lo descomprimimos en una carpeta en Disco Local C:



GUIA INSTALACION EN WINDOWS: 
HOW TO INSTALL NGINX WEBSERVER ON WINDOWS 10/8/7

minuto 0.29 clase proxy:
explica comandos para windows para operar con nginx
hay que posicionarnos en la carpeta donde estamos

y poner:

 ./nginx.exe -s reload

esto se usa mucho para cuando hacemos un cambio recargamos con esto el servidor

IMPORTANTE DESPUES DE HACER CADA COSA HACER EL 

./NGIX.EXE -S RELOAD

la movida de nginex se crean archuvos con extension .conf
y dentro de esas .conf va una base siempre asi:
----------------------------------------------------------
events {

}

http {
    server {
        listen: 80;
        server_name nginx-handbook.test;

        return 200 "hello from port 80!\n"
    }
        server {
        listen: 8080;
        server_name nginx-handbook.test;

        return 200 "hello from port 8080!\n"
    }
}

-----------------------------------------------------------

podemos crear varios servidores asi temporales y lo que pongamos dentro de server {}
va a ser la configuracion de ese servidor


PARA CREAR UNA CARPETA TIPO ESTÁTICA DONDE VA A IR TODO LO DE FRONT

EN LA CARPETA QUE DESCOMPRIMIMOS DE NGINX:
ESTA DENTRO DE LA CARPETA HTML TODO

Y EN EL CODIGO PONEMOS ROOT HTML
DENTRO DE HTTP{

}

----------------------------------------

PARA DEFINIR RUTAS CON NGINX:

DENTRO DE 
HTTP {
    SERVER {
        LISTEN 80;
        SERVER_NAME NGINX-HANDBOOK.TEST;

        LOCATION /INICIO {
            RETURN 200 "ESTA ES LA RUTA DE INICIO"

        }
            (cuando ponemos de esta forma todo lo que empieza con /inicio
            va a mostrar ese mensaje
            puede ser un /inicio-algomas
            y va a seguir mostrando eso)

        LOCATION = /IGUALACION {
            RETURN "DEVUELVO A IGUALACION
        }
            (cuando ponemos el = antes, buscamos un match exacto de la ruta)


        LOCATION ~ /REGULAR[0-9] {
            RETURN 200 "LOCATION CON EXPRESION REGULAR"
        }
            ( esto hace que podamos poner cualqueir numero luegode la / )

        LOCATION ~* /MAYUSCULA[0-9] {
            RETURN 200 "DEVUELVO CON MAYUSCULA.\n"

            ( lo mismo que el anterior pero con el * se vuelve case sensitive la ruta
            gralmente queremos que distinga las mayusculas en las rutas )
        }
    }
}

---------------------------------------------

Para crear varios servidores a la vez con NGINX:

events {

}

http {
    server {
        listen 80;
        server_name ngnix-handbook.text

        return 200 "hello from port 80 \n"
    }

    server {
        listen 8080;
        server_name ngnix-handbook.text

        return 200 "hello from port 8080 \n"
    }
}


-------------------------------------------------------------

PARA INCORPORAR un HTML Y CSS al servidor:
hay que mandarle donde esta la ruta de nuestros archivos estaticos
se hace poniendo dentro de:

http {

    types {
        text/html html;
        text/css css;
    }

    server {
        listen 80;

        root /var/www/html; 
    }
}

lo que esta dentro de types significa:
los archivos que terminen en html, que proxy los trate como html
los archivos que terminen en css, que proxy los trate como css
si no ponemos esto y hacemos los archivos, no los va a tomar



y lo que esta en root es la carpeta donde vamos a poner los archivos

----------------------------------------------------

otra forma facil de decirle que types de archivos vamos a usar
es importar el mime.types
es un archivo q esta donde instalamos todo
y tiene todos los tipos de archivos segun como terminan ya armados

para importar es asi:

http {
    include     mime.types;

    server {
        listen 80;
        server_name localhost;
    }
}


IMPORTANTE TERMINAR CADA SENTENCIA/RENGLON CON UN PUNTO Y COMA ;

EN WINDOWS USAMOS ROOT HTML (LLEVA A LA CARPETA DONDE INSTALAMOS TODO)

en esa carpeta podemos poner fotos, gifs, archivos html/css/js

----------------------

VARIABLES EN NGINX:

events {

}

http {
    
    server {
        
        listen 80;
        server_name localhost;

        location = /variables {
            return 200 " Host - $host\nURI - $uri\nARGS - $args"
        }
    }
}

los $host - $args - $URI 
SON VARIABLES PREDETERMINADAS DE NGINX Y MUESTRAN X EJEMPLO ESOS DATOS CUANDO LAS LLAMAMOS
SE PUEDEN ENCONTRAR EN:
HTTPS://NGINX.ORG/EN/DOCS/VARINDEX.HTML


-----------------------------------------------------

TRY FILES

es una forma de decirle a NGINX como tiene que trabajar en la resolucion

si tenemos archivos estaticos + endpoints
como sabemos si lo q pedimos es un archivo o un endpoint
x ej si /css/estilos.css es un archivo o un endpoint

entonces le decimos como tiene q trabajar

server {
    listen 80;
    server_name localhost;

    root /var/www/html;  -> aca vemos en la carpeta estatica si existen los archivos

                            si no existe lo buscamos como si fuese una ruta de location /

                            queda asi:

    try_files $uri $uri/ /not_found;    

                            si no existe, ejecutate la ruta /not_found

    location /not_found {
        return 404 "sadly, you've hit a brick wall \n"
    }


}

--------------------------

PROXY INVERSO
sirve para poner location / {
    
}
y eso significa que todo lo que pongamos como endpoint , es como un *
lo mande a tal puerto o haga tal cosa

events {

}

http {

    include mime.types

    server {
        listen 80;
        server_name ngnix.test
        
        location /ejemplo1 {
            proxy_pass "http://nginx.org/ 
        }
    }
}

-------------------------------------------------------

BALANCEADOR DE CARGA

events {

}

http {

    upstream mibackend {
        server localhost:3001;
        server localhost:3002;
    }

    server {
        listen 80
        server_name nginx-handbook.test;

        location / {
            proxy_pass http://mibackend;
        }
    }
}

IMPORTANTE

A ESTO HAY QUE SUMARLE EL ecosystem.config.js
algo asi por cada servidor:

module.exports = {
    apps [

{
    name: 'app1',
    script: 'dist/index.js',
    watch: true,
    autorestart: true;
    args: '--puerto=3001'
},
{
    name: 'app2',
    script: 'dist/index.js',
    watch: true,
    autorestart: true;
    args: '--puerto=3002'
},
{
    name: 'app3',
    script: 'dist/index.js',
    watch: true,
    autorestart: true,

    instances: 'max',

    args: '--puerto=3002'

}


{
    script: './service-worker',
    watch: ['./service-worker']
    },
    ]
}



para que corra en modo FORK 
no se le pasan en la config:

instances: 'max'

si le pasamos esa instancia, va a correr en modo CLUSTER
que significa que reparta el servidor entre todos los nucleos que tiene mi PROCESOS

EN ESTE CASO LA APP3 CORRE EN MODO CLUSTER, Y LAS PRIMERAS 2 EN MODO FORK
tambien se puede poner un numero que no sea 'max' en instances

-------------------------

la idea es crear una aplicacion q se va a dividir en 2
son 2 aplicaciones iguales que se escuchan en puertos distintos
como que lo estamos duplicando

y NGINX empieza a repartir equitativamente entre estos 2 servidores

SIRVE PARA QUE SE REPARTA EN PARTES IGUALES CADA ENTRADA DE UN CLIENTE AL servidor
si ponemos los 2 puertos como arriba
y recargamos la pagina, va a mandarnos una vez a cada puerto de esos 2

esto lo hace NGINX

el codigo uno solo
pero gracias a q le podemos pasar por argumento q puerto queremos escuchar 

al nginx le llegan las solicitudes y sabe q tiene esos 2 y los va repartiendo

----------------------------------------------------------

PARA HACER UNA GRAN APP BALANCEADA ES IMPORTANTE:

USAR EL MODO CLUSTER PONIENDO INSTANCES: 'MAX'

Y A ESO SE SUMA:

PONER EN HTTP {
    UPSTREAM MIBACKEND {
        SERVER LOCALHOST:3001;
        SERVER LOCALHOST:3002;
        SERVER LOCALHOST:3003;
    }
}

AHI TENEMOS 3 SERVIDORES AL MISMO TIEMPO FUNCIONANDO CON EL MISMO CODIGO
Y A ESO SE LE SUMA QUE SE REPARTE ENTRE LOS NUCLEOS DE LA PROCESOS

---------------------------------------------------

Para el desafio

agregar un parametro mas a la ruta del comando
q permita ejecutar en modo cluster o modo fork

es como el ejemplo de loadbalancer
pero nosotros estamos usando minimist 

la onda es que si ponemos en modo FORK arranque como siempre
pero si ponemos en argumento modo CLUSTER la idea es que hagamos por codigo la ejecucion del cluster

eso esta en 29-cluster -> 01-cluster 

donde creamos los hilos y cuando uno muere crea el otro
es lo de:

---------------------------------------------------------

import cluster from 'cluster';
import os from 'os';
import server from './services/server';

const numCPUs = os.cpus().length

const modoCluster = (aca armar el codigo para ver si recibi el argumento --modo=cluster)

 if (cluster.isMaster) {
    for (let i = 0; i < numCPUs; i++) {
        cluster.fork();
    }

    cluster.on('exit', (worker, code) => {
        cluster.fork();
    })
} else {
    const PORT = 8080;

    server.listen(PORT, () => {
        console.log('Servidor express escuchando en puerto')
    })
}


-------------

despues habria que poner para iniciar el servidor asi:

node dist/index.js --modo=fork

o

node dist/index.js --modo=cluster

usar minimist

------------------------------

CONSIGNA 2

ES SUMANDO A ESTO EJECUTARLO CON FOREVER
Y PROBARLO CON PM2

-------------------------

CONSIGNA 3 NGINX

la misma app que tenemos, la levantamos en el puerto 8081
despues en el archivo de configuracion: 
nginx.conf
todo lo que vaya a 

location /api/randoms {
    proxy_pass http://localhost:8081;
}

location / {
    proxy_pass http://localhost:8080;
}

luego:

en el ecosystem.config.js

en los args:    '--puerto=8080'
y               '--puerto=8081'

Y LUEGO:

PARA CORRERLO EN 8081, 8082, 8083, 8084

se pone en:

http {
    upstream mibackend {
        server localhost: 8081;
        server localhost: 8082;
        server localhost: 8083;
        server localhost: 8084;

    }

    server {
        listen 80;
        server name localhost;

        location / {
            proxy_pass http://mibackend;
        }
    }
}


-------------------------------------------------------------

TECNICAS PARA NO BARDEAR EN PRODUCCION CUANDO HAY MUCHOS clientes

EN EL CODIGO:

COMPRESION

SE COMPRIME EN UN GZIP
SE REDUCE EL TAMAÑO DEL CUERPO DE RESPUESTA Y AUMENTA LA VELOCIDAD DE LA APP
USAMOS GZIP, UN MIDDLEWARE DE COMPRESION DE NODE PARA APLICACIONES express

SI TENEMOS UN TRAFICO ELEVADO EN PRODUCCION NO ES LA MEJOR OPCION

SOLO HAY QUE IMPORTAR 

import express from 'express';
import compression from 'compression';

const app = express();

app.use(compression())

--------------------------------------------

si probamos esto en local no se mostraria la rapidez ,
hay que probarlo en produccion por ejemplo con GLITCH

y ahi es donde tarda en llegar al info de un servidor

------------------------------------------

IMPORTANTE SIEMPRE EN NODEJS - PARA MEJORAR EL RENDIMIENTO


- NO UTILIZAR FUNCIONES SINCRONICAS
TRATAR DE UTILIZAR TODO CON FUNCIONES ASINCRONICAS QUE ES LA CLAVE DE NODEJS

-EVITAR SU USO EN PRODUCCION

LA UNICA VEZ QUE SE PUEDE USAR LA FUNCION SINCRONICA ES EN EL ARRANQUE INICIAL 
OSEA EN EL INDEX.js

EN .ENV PONER:

NODE_ENV=PRODUCTION

ESTO HACE QUE EXPRESS "SE PONGA LAS PILAS" Y PUEDE FUNCIONAR HASTA 3 VECES MAS RAPIDO 

-----------------------------------------------

REALIZAR UN REGISTRO CORRECTO

ACA ENTRAN LOS CONSOLE.LOG() O CONSOLE.ERR()  QUE SON COMUNES EN DESARROLLO
PERO EN PRODUCCION NO SIRVEN PORQUE SON SINCRONICAS

PARA PRODUCCION:
- VAMOS A USAR LA LIBRERIA DE DEBUG
QUE SIRVE PARA DEPURACION

- Y PARA REGISTRAR LA ACTIVIDAD DE LA APLICACION,
QUE EN VEZ DE USAR CONSOLE.LOG(),
VAMOS A USAR BIBLIOTECAS DE REGISTRO COMO 
WINSTON O BUNYAN

---------------------------------------------

MANEJAR LAS EXCEPCIONES CORRECTAMENTE

las aplicaciones Node se bloquean cuando encuentran una excepcion no capturada
si no manejamos las excepciones la aplicacion Express se bloquea y queda fuera del intermediario

si nos aseguramos de que la aplicacion se reinicie automaticamente mas abajo,
esta se recupera de un bloqueo

PARA ESTO SE UTILIZA TRY / CATCH 
Y PROMISES

-------------------------------------------------

CAMBIOS EN EL ENTORNO QUE PODEMOS HACER (EN VEZ DEL CODIGO QUE ES LO DE ARRIBA)

- CREAR UNA VARIABLE DE ENTORNO NODE_ENV Y PONERLA COMO PRODUCTION
ASI HACEMOS QUE EXPRESS MISMO SE COMPORTE EN MODO PRODUCCION Y MEJORA SU RENDIMIENTO

ESTO LO HACEMOS DESDE LA TERMINAL O USANDO DOTENV CREANDO EN NUESTRO .NODE_ENV
Y LO METEMOS HAI JUNTO CON EL STRING DE CONEXION Y PUERTOS


ES IMPORTANTE:

- HACER QUE LA APP SE REINICIE automaticamente
USANDO FOREVER O PM2 LOGRAMOS QUE SI MUERE HAYA ALGO QUE LA REINICIE automaticamente
ES CLAVE PARA QUE SIEMPRE ESTE VIVE


IDEAL ES USAR PM2

- EJECUTAR LA APP EN MODO CLUSTER 
(SISTEMA MULTINUCLEO PARA MULTIPLICAR EL RENDIMIENTO DE LA APLCIACION)
USANDO 1 PROCESO POR CADA NUCLEO QUE TENGAMOS
ACA TAMBIEN ENTRA PM2

SE INSTALA PM2
SE CONFIGURA 
Y SE PONEN LOS INSTANCES: 'MAX'

Y LISTO, NO ES NECESARIO TOCAR EL CODIGO 

- ALMACENAR LAS RESPUESTAS EN CACHE 
ESTO LIBERA AL BACKEND DE RESPONDER UNA Y OTRA VEZ LO MISMO


ACA PODEMOS USAR NGINX O TAMBIEN REDIS

- UTILIZAR UN BALANCEADOR DE CARGAS

ESTO ES NGINX
DONDE PONEMOS LA APP EN MODO CLUSTER
Y ADEMAS REPLICARLA EN VARIOS PUERTOS A LA VEZ QUE LUEGO VAN AL PROXY QUE LOS REPARTE
USANDO UN PROXY INVERSO ADELANTE MULTIPLICAMOS LA CAPACIDAD DE NUESTRA APLCIACION

LO IDEAL SIEMPRE ES USAR UN SERVIDOR EXPRESS CON UN PROXY INVERSO HECHO CON NGINX 

EL PROXY INVERSO SE COLOCA DELANTE DE UNA APLCIACION WEB Y REALIZA OPERACIONES DE SOPORTE EN LAS SOLICITUDES, ANTES DE DIRIGIR LAS SOLICITUDES A LA APLICACION 
PUEDE MANEJAR LAS PAGINAS DE ERORRES, LA COMPRESION,  EL ALMACENAMIENTO EN CACHE, EL SERVICIO DE ARCHIVOS Y EL EQUILIBRIO DE CARGA, ENTRE OTROS.





-----------------------------------------------------------------------------------------------------------------


LOS LOGS SON LOS REGISTROS DE LA ACTIVIDAD DE NUESTRA APP

INGRESANDO A LOS LOGS SABRIAMOS SI ESTA FUNCIONANDO O NO

SI NOS DICEN QUE NO FUNCIONA LA APP
ENTRAMOS A LOS LOGS PARA VERIFICAR DONDE ESTA EL ERROR
AHI ESTAN LAS PRUEBAS DE TODO

LA FORMA MAS FACIL ES PONER CONSOLE.LOG A TODO

LIBRERIA QUE HACE ESTO DE GUARDAR LOS LOGS CON HORA Y DIA:

log4js

SE INSTALA Y SE IMPORTA

luego dentro de alguna funcion ponemos

export const funcion1 = () => {
    const logger = log4js.getLogger();

    logger.level = 'warn';
}

tambien hay otras funciones como
logger.trace
logger.debug 
logger.info (si quiero que sea algo informativo) 
logger.warn (para avisar algo q valga la pena pero q la app sigue funcionando)
logger.error (para imprimir el error)
logger.fatal (para cuando la app murio)

estan en orden desde el menos importante al menos importante em lo que es el aviso
 
ENTONCES SI PONEMOS EL NUVEL DESDE EL QUE QUEREMOS IMPRMIR
LOGGER.LEVEL = 'WARN';
NOS IMPRIME LOS LOGS DESDE ESE NIVEL HACIA ARRIBA EN IMPORTANCIA, todos

PODEMOS DECIRNOS QUE MANDE LOS LOGS A UN ARCHIVO

----------------------

PARA IMPRIMIR NUESTROS LOGS EN UN ARCHIVO 
- USAMOS APPENDER, QUE DICE A DONDE VAMOS A MANDAR ESO 
- USAMOS CATEGORIES,  

export const funcion2 = () => {
    log4js.configure({
        appenders: {
            fileAppender: {type: 'file', filename: './logs/example-1.log'}
        }
        categories: {
            default: {appenders: ['fileAppender'], level: 'error'}
        }
    });

    const logger = log4js.getLogger();

    logger.level = 'warn';

}

en el appender creamos una salida que le ponemos como nombre fileAppender
que sera del tipo file
y sera ubicado en la carpeta /logs 
en el archivo example-1.logs
(osea, voy a crear una salida donde los logs vayan a un archivo, que es el filename: '')

para utilizar esta salida tenemos que configurar una categoria
en categories: 
creamos nuestros loggers
ahi le decimos que appenders tiene que utilizar

DONDE GUARDAR ESTOS ARCHIVOS : 
HAY PLATAFORMAS EN LA NUBE (CLOUDWATCH, DATALOG, HAY ALGUNOS GRATIS )

DATALOG:

ES UNA HERRAMIENTA MUY UTIL 

NOSOTROS LES PASAMOS NUESTROS LOGS 
Y NOS ARMA UNA METRICA DE LOS MOVIMIENTOS QUE HUBO 




O GUARDARLO EN EL MISMO SERVIDOR DE MI BACKEND
PERO HAY QUE TENER CUIDADO PORQUE SE VA A LLENAR ESE ARCHIVO
ENTONCES PODEMOS PONER QUE A LOS 15 DIAS BORRE LOS LOGS ANTERIORES, O ALGO ASI

----------------

LOGS EN ARCHIVO:

ES LO MISMO PERO ANTES DE LOS LOG HAY QUE PONER UN LOG4JS.CONFIGURE({ })

SI QUEREMOS SUMAR UN APPENDER SE PONE ASI:

    log4js.configure({
        appenders: {
            fileAppender: {type: 'file', filename: './logs/example-1.log'}
            consola: {type: 'console'}
        }
        categories: {
            default: {appenders: ['fileAppender', 'consola'], level: 'error'}
        }
    })

------------------

esto haria que se imprima en un archivo, y tambien en la consola

------------------------------------------------------------------------

YA CON ESTO PODRIAMOS IMPLEMENTARLO EN NUESTRAS APLICACIONES
Y EN VEZ DE PONER CONSOLE.LOG() EN LAS FUNCIONES
HAY QUE ACOSTUMBRARSE A PONER:
LOGER.WARN()
O LOGGER.INFO()


-------------------------------------------------------------------------------------

WINSTON (es como log4js)

ES UNA LIBRERIA QUE SOPORTA PARA MANDAR A ARCHIVOS, A CONSOLA, NUBE... SE BANCA TODO
A ESTO TAMBIEN SE LE DICE QUE TIENE SOPORTE PARA MULTIPLES TRANSPORTES DISEÑADA PARA EL REGISTRO

UN TRANSPORTE ES UN DISPOSITIVO QUE NOS PERMITE ALMACENAR MENSAJES EN UN ARCHIVO O CONSOLA

LA LOGICA ES PARECIDA A log4js, tiene nombres parecidos los logger.debug, logger.error, etc pero parecidos

LA DIFERENCIA ES QUE NOS MANDA LOS LOGS EN UN OBJETO
CADA LOG EN UN OBJETO
SON MEJORES PARA HACER BUSQUEDAS DESPUES


--------------------------------------------------------------------------------------

PINO 

ES COMO log4js y WINSTON

LO QUE TIENE DE BUENO ES QUE EN LOS
LOGGER.trace
LOGGER.FATAL 

PODEMOS PASARLE OBJETOS

export const ejemplo1 = () => {
    const logger = pino({ level: 'trace' })

    logger.trace({
    mensaje: 'Imprimimos trace',
    nombre: 'cristian',
    edad: 22
    });

}

---------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------

PROFILING Y DEBUG

PARA QUE NOS SIRVE EL PROFILING?
HACE TESTS DE CARGA/ESTRES QUE SIMULA COMO SE VA A COMPORTAR NUESTRA APP EN PRODUCCION

ARTILLERY 

es una dependencia de Node que nos permite obtener informacion a nivel cuantitativo
sobre como se va a comprortar nuestra app en produccion
sirve para cuando las paginas van a recibir muchos clientes y prevenir problemas

nos da pruebas reales para darle a nuestro cliente

SE INSTALA ARTILLERY DE FORMA GLOBAL
NPM I ARTILLERY -g

 y en el package.json van:
 como en el ejercicio de cluster/fork
 "start:fork": "node dist/index.js --puerto=8081", (esto con el minimist armado en el index.js para pasar parametro de puerto)
 "start:cluster": node dist/index.js --puerto=8082 --cluster",

 "artillery:fork": "artillery quick --count 50 n- 40 http://localhost:8081/prime?max=100000",
 "artillery:cluster": "artillery quick --count 50 n- 40 http://localhost:8082/prime?max=100000",

el --count 50 simula que hay 50 clientes
el -n 40 simula que cada cliente hace 40 requests

este sería un test rapido "a lo bruto", le pegan todos juntos al mismo tiempo
-----------------------------------------------
luego ARTILLERY nos permite hacer una segmentacion

si tenemos corriendo fork y cluster en los puertos 8081 y 8082 al mismo tiempo

---------------------------------------

FORMATO .YML EN ARTYLLERY

ES UN FORMATO AMIGABLE, ES COMO UN OBJETO PERO SACA LAS LLAVES Y CORCHETES, COMAS...

UN ARCHIVO .YML ES COMO UN PUG

hay un JSON - YAML CONVERTER PARA VER QUE onda

LOS ARRAY SE PONEN ASI

HOBBIES:
-FUTBOL
-PLAY
-ASADO

en vez de:

{
    "hobbies": ["futbol", "play", "asado"]
}

LOS ARRAY DE OBJETOS ASI:

arrayCalificaciones:
-materia: ingles
 nota: 8
-materia: matematica
 nota: 8

 en vez de:
 {
    "calificaciones":  
    [
        {
            "materia": "ingles", "nota": 8
        },
        {
            "materia": "matematica", "nota": 8
        }
    ]
    
 }

------------------------------------------

EN ARTILLERY SE ESCRIBE UN ARCHIVO .YML CON TODA LA CONFIGURACION QUE VAMOS A USAR 

config:
    target: 'http://localhost:8081;

    phases:
        -duration: 5
        arrivalRate: 50 (50 clientes se van a crear cada 5 segundos)
        name: Warm up 
    payload:
        path: 'keys.csv'
        fields:
            - 'id 

    scenarios:
        -name: ''
        flow:
            - get: 
                url: '/api/materials'
            - think: 10
            - get:
                url: '/api/materials?id={{id}}'


eca lo que hace es pedir los materiales, esperar 10 segundos 
y luego pedir materiales por ID

en payload vamos a usar ciertas cosas que estan en otro archivo llamado:
keys.csv

ahi tenemos IDs que tenemos en nuestra base de datos,
entonces los agarra para el get by ID 

---------------------------------------------------

COSAS QUE HAY QUE HACER PARA TENER UN SERVIDOR BALANCEADO Y QUE SE BANQUE MUCHOS clientes

- MODO CLUSTER PARA QUE TRABAJE CON TODOS LOS NUCLEOS DE LA CPU 
- NGINX PARA QUE TRABAJEMOS EL MISMO SERVIDOR EN VARIOS PUERTOS A LA VEZ QUE PASAN POR EL NGINX AL FINAL Y ES TODO UN SERVIDOR 
- EVITAR CODIGO SINCRONICO SIEMPRE 
- EVITAR CONSOLE.LOGS, USAR LOS LOGGERS QUE RECONTRA VAN 


--------------------------------------------------------------------------

PROFILING

EL PROFILING ES UN ANALISIS DE RENDIMIENTO 
ANALIZAMOS CIERTAS PARTES DE CODIGO PARA DETECTAR POSIBLES CUELLOS DE BOTELLA

en el package.json hay que meter estos script:

"start:profiling": "node --prof --logfile=foo.log --no-logfile-per-isolate dist/index.js",
"start:inspect": "node --inspect dist/index.js"


CURL 

ES UN CLIENTE PARA REALIZAR PETICIONES HTTP DESDE LA TERMINAL 
SE UTILIZA MUCHO PARA EJECUTAR SCRIPTS 

PARA HERRAMIENTAS COMO AXIOS POR DEBAJO SE USA ALGO COMO ESTO 

NODEJS AXIOS NOS ESCRIBE EL CODIGO 

LA VERSION AXIOS NATIVA ESTA BUENA 

--------------

PARA ENCRIPTAR CONTRASEÑAS SE USA UNA LIBRERIA LLAMADA CRYPTO 

---------------------------------

CLAVES PARA PROFILING

SE HACE UN ARCHIVO CON CURL

ESTE TIENE SCRIPTS QUE SE EJECUTAN SOLOS COMO UN POSTMAN
CUANDO LE HACEMOS NODE /ARCHIVO
extension .sh 


X EJEMPLO CREA UN USUARIO (1 LINEA CURL)
Y PRUEBA 100 REQUESTS CON ARTILLERY

script para CURL : 

--------------------------------------------------

curl -X get "http://localhost:8080/newUser?username=gonzi&password=1234"

artillery quick --count 10 -n 50 "http://localhost:8080/autorizarUser?username=gonzi&password=1234" >     result_bloq.txt 

---------------

el > manda resultados a un archivo con ese nombre 

--------------------------------------------

Y HAY UNA FORMA DE EN VEZ DE MOSTRAR EN CONSOLA, Q MANDE A UN ARCHIVO EL ANALISIS 

QUEDAN LOS SCRIPTS ASI:

primero:
node --inspect /scritps/script1.sh
(puede ser asi:
"start:inspect": "node --inspect dist/index.js",
"start"profiling": "node --prof --logfile= foo.log --no-logfile-per-isolate dist/index.js")

el --prof crea un archivo nuevo 
(en este caso isolate-0x1241241-412-v8.log) 
en este archivo tenemos la info pa saber si nuestra app funciona bien o no

esto nos da un archivo feo hecho para q lea una maquina 

entonces tenemos que convertirlo asi:

node --prof-process [nombreArchivoIsolate].log > [archivoSalida].txt 

el > crea un archivo con el nombre q pongamos 

y en ese archivo nos tira cuanto tiempo estuvo el procesador haciendo ciertas cosas
lo + imp es la cant de procesador q le costo hacer cada trabajo (medido en pulsos -> ticks)

----------------------------------------------

el --inspect 
(node --inspect dist/index.js)

ejecuta la aplicacion pero con el profiling de NodeJS, y que node haga su trabajo de mirarla bien

ACA ES DONDE HAY QUE TENER UN SCRIPT .SH 
DONDE METEMOS 

curl -X get "http://localhost:8080/newUser?username=gonzi&password=1234"

artillery quick --count 10 -n 50 "http://localhost:8080/autorizarUser?username=gonzi&password=1234" >     result_bloq.txt 

(esto es un proceso automatizado que ejecute la primera ruta )
y con artillery la segunda linea vamos a crear 10 usuarios que le van a pegar 50 veces al siguiente endpoint
y con > result.bloq.txt LO MANDAMOS A UN ARCHIVO LOS RESULTADOS 

--------------------

AUTOCANNON 

npm i -g autocannon 0x (aca instalamos autocannon y 0x)

es como artillery 

se puede ejecutar de 2 maneras distintas: 
- a dif de artillery, se puede ejecutar a traves de un script JSX


0x 

es otra libreria de Node. que nos ayuda a crear un flame graph (grafico de flama )
este grafico nos muestra el rendimiento de nuestra aplicacion 
xq nos muestra los puntos calientes de la aplicacion

autocannon puede reemplazar a Aritllery, 0x no
0x es algo nuevo 

AUTOCANNON 

tambien lleva sus scripts automatizados 

pero tienen diferentes opciones 

-c 
numero de clientes en simultaneo que vamos a llamar 

-d
cuanto tiempo va a correr autocannon (en segundos)

-b
body para mandar en las request 

-m
que metodo HTTP vamos a usar (por defecto esta 'GET')

-w
si va haber un intervalo de warmup o van a estar todos pegando a la vez 

-L 
numero de milisegundos entre cada peticion (por defecto es '1')
intervalo entre cada cliente va a pegar al endpoint 

------------------------------------------------

(primero creamos el usuario)

curl -X GET "http://localhost:8080/signup?username=gonzi&password=1234" 

(luego ejecutamos autocannon al endpoint de autenticacion)

autocannon -c 100 -d 15 ""http://localhost:8080/login?username=gonzi&password=1234" 

----------------------------------

luego en package json
en vez de ejecutar node, ejecutamos 0x 

"start": "0x dist/index.js",
"dev": "nodemon",

IMPORTANTE: 
x temas de permisos 
mejor ejecutar el 0x dist/index.js en una consola comun aparte 

luego en otra consola comun ejecutamos el script del curl -X get 


------------------------------------

autocannon tambien se puede ejecutar como un script de JS normal 

ALTERNATIVA A 0x es: CLINIC 

es un flame graph pero mas cheto, se instala. se ejecuta los script para que le peguen al endpoint 
y luego se ve el analisis con graficos piolas 

npm i -g clinic 

mismo sistema que con 0x

AUTOCANNON O ARTILLERY SON PARA SIMULAR LOS CLIENTES QUE LE PEGAN A NUESTRA APLICACION 

y para VER RENDIMIENTO en nuestra aplicacion: 
profiling comun:
( con el node --prof dist/index.js, 
este nos generaba un archivo que luego habia que 
hacerle node --prof-process resultado.log > resultadoLindo.log 
y nos mostraba el numero de ticks(latidos de la app )
)
profiler de google chrome: 
(lo mismo pero se corre con: 
node --inspect dist/index.js 
luego en el navegador chrome ponemos: 
chrome://inspect 

abrimos el devTools
ponemos a grabar nuestra sesion/ para obtener data de profiling 
cuando terminamos de grabar 
podemos ver los tiempos de demora en nuestro codigo y donde fueron 
)
0x:
nos da el grafico de flama 
clinic : 
lo mismo pero mas cheto 

----------------------------------------------------------------------------------------------------

CONTROL DE VERSIONES 

sirve para organizar a los grupos de programadores o nosotros mismos 
se registran los cambios que se hicieron 

cada desarrollador se baja una copia local de la NUBE
y con esa copia podemos hacer lo que querramos 
pero no afecta al proyecto original en el repositorio central
asi podemos experimentar sin afectar a la fuente 

cuando se trabaja en el mismo sector de codigo desde 2 diferentes lugares 
cuando ambos suban su codigo habra un conflicto 
en las empresas se arregla hablando con el otro programador y decidiendo que va y que no 

con estos controles podemos ver 
cuando fueron, quienes los hizo y como 
permite desarrollar versiones de un mismo proyecto a la vez, o ramificarlos 

las BRANCH son ramas / copias del proyecto original de la rama original 
y a partir de ahi se clona y cada proyecto sigue su camino 
entonces podemos trabajar en esa rama, ir guardando y una vez que funcionó
si queremos podemos fusionar estos cambios en la rama principal en algun momento 
o se puede descartar 
la fusion de 2 branches se llama MERGE 

ESTO ES EL DIA A DIA DE UN PROGRAMADOR 

en las empresas hay una rama principal llamada main como la de github 

cuando hay que hacer un trabajo, creamos una rama a partir dela principal 

y ahi nos hacemos los cambios y probar cosas, hacer lo que nos piden 
una vez testeado solicitamos la fusion de nuestra rama con la principal 
esto es una PULL REQUEST / PR 
esto permite q la rama principal solo se suban los cambios que hay que subir 

------------------

GIT 

herramienta para llevar a cabo el control de versiones 
el mas utilizado 

mas alla de que usemos github, gitlab, gitbucket 
(son todos servidores de repositorios, pero es el mismo concepto)
la que va es github 

amazon tiene su repositorio
asure y goodflow tambien 
(pero nadie le gana a github)

EN LA DESCRIPCION DEL COMMIT SIEMPRE VA EL CAMBIO QUE HICIMOS 


git add .                                       (el . hace que mandemos todo, sino podemos elegir por lineas )
git commit -m "descripcion del commit"          (la -m es para mandar al MAIN)
git push -u origin main


git pull                                traemos los cambios que se hayan hecho

->  editamos el codigo 

        -> publicamos/creamos la rama (branch) 
            -> subimos cambio 
                -> hago mi commit 
                    -> push
                        -> el MERGE es para unir la rama al MAIN 

cuando hay conflictos de merge se crea un PULL REQUEST 
    -> pide que se resuelvan los conflictos MANUALMENTE 
        -> esto pasa cuando editamos algo que ya no existe por un commit anterior (puede ser de otra persona del grupo de programadores)

se resuelve asi:
    -> yendo a la rama MAIN 
        -> hacemos git pull 
            -> aparece el nuevo cambio 
                -> una vez q tenemos la ultima version del main VOLVEMOS A MI RAMA 1 
                    -> escribimos le commanod GIT MERGE (nombre rama que quiero mergear)
                    (esto agarra mi rama main del local, y lo fusiona con la rama 1, se hace lo inverso )
                    (parados en rama 1, vamos a decir fusioname la rama MAIN a esta rama)
                    

<<<<<< HEAD (current change)

LO QUE ESTA ARRIBA ES LO QUE ESTAMOS INTENTANDO CAMBIAR 

===========

ACA ABAJO VA LO QUE YA ESTABA CAMBIADO 

-------------------------------------------------------------

Hay varias opciones, aceptar un cambio, el otro o los dos.

-------------------------------------------------------------------

CLOUD COMPUTING 

ES COMO LA ELECTRICIDAD QUE NO TENEMOS NUESTRO GENERADOR DE ENERGIA 
UTILIZAMOS LA QUE NOS DA EL PROVEEDOR 

CLOUD COMPUTING ES LA IDEA Q LE PAGAMOS A UN PROVEEDOR LOS RECURSOS QUE NECESITEMOS
(MAQUINAS VIRTUALES PARA PONER APP, DISCOS PARA ALMACENAMIENTO, SOLUCIONES DE NETWORKING/SEGURIDAD )

INFRAESTRUCTURA COMO SERVICIO: EL PROVEEDOR NOS OFRECE COMPUTO Y ALMACENAMIENTO 
    Y EL CLIENTE TIENE RESPONSABILIDADES DE BAJO NIVEL
    (AMAZON NOS ASEGURA Q NADIE VA A TOCAR ESA MAQUINA, PERO NOSOTROS TENEMOS QUE INICIAR NODE Y TODAS LAS MOVIDAS)
    SOMOS EL ENCARGADO DE QUE FUNCIONE 

PLATAFORMA COMO SERVICIO: ESTE NIVEL ES EL MAS COMODO PARA DESARROLLADORES 
    (NOS OLVIDAMOS DEL BALANCEO DE CARGA CON NGINX, O SI LA PC TIENE WINDOWS LINUS O MAC XQ SE ENCARGAN DE ESO)

SOFTWARE COMO SERVICIO: ES UNA CAPA MAS,
    COMO PARA ALGUIEN QUE NO SEPA DESARROLLAR, NOS DAN EL SERVICIO PARA GUARDAR COSAS EN AL NUBE
    VENDRIA A SER GOOGLE DRIVE ESTO 

----------------------------------------------------------------------------------


HEROKU
es una plataforma en la nube que ofrece servicios
para alojar o implementar aplicaciones web

nos crea un dominio

HAY QUE CREARSE UNA CUENTA EN HEROKU 

logear
crear nueva app
el deployment method va a ser github
(nos conectamos a nuestro repositorio)
 
 cuando creamos app:
 activar deploy automatico 

 y deploy branch en master 

IMPORTANTE: 

    - como cargar las variables de entorno:
    settings -> config vars -> keysvalues
    ahi va:
    ENV_EJEMPLO = INDEPENDIENTE 

    - NO setear puerto dentro del codigo nuestro, porque lo hace HEROKU y tira bardo 
        se hace asi: 
            export const PORT = process.env.PORT 
        (como en glitch)
        heroku define el puerto - crea esta variable de entorno por nosotros 
        en el proceso de deploy, heroku primero busca un puerto libre dentro de los suyos
        y luego setea esta variable de entorno 

--------------------------------------------------------

para subir cambios:
se hace un push y heroku baja los ultimos cambios y reconstruye la aplicacion 
solo con un push estaría

x eso es clave tener linkeado a GITHUB 
asi cuando hacemos push HEROKU se da cuenta automaticamente

ESTO ES SETEANDO EL DEPLOY AUTOMATICO

PARA HACER EN BABEL 
scripts:

    "build": "npm install && babel src --out-dir dist",
    "start": "npm run build && node ./dist/index.js",
    "dev": "nodemon --exec babel-node .src/index.js",

ASI ESTA LISTO PARA SUBIRSE A HEROKU:
(el start hace el buildeo + instalacion de todo 
y inicia la aplicacion )


-----------------------------------------------------------------------------------

AWS 

siempre que creemos usuario usar la doble autenticacion xq te roban todo 
se puede poner tarjeta para probar y despues sacarla 

ELASTIC BEANSTALK

- es un servicio que se encarga de administrar la infraestructura de nuestra aplciacion 
(se encarga de levantar las maquinas virtuales, cargar nuestro codigo en esas, mantenerlas, la escalabilidad)
- tambien ajusta el escalado de la aplcacion automaticamente:
si seteo que minimo siempre haya 1 maquina corriendo y maximo 10 
como se da cuenta cuando levantarlas para no tener q pagar 10 maquinas todo el tiempo
hay una logica: 
    -> levanta una maquina 
    -> cuando la capacidad el procesador llega al 80%, empieza acrear instanacias para ayudarlo
    -> agregan otra maquina 
    (se cobra por hora de uso de cada maquina)

---------------------------------------------------------------------------

SERVICIOS DE AWS CLAVES: 
    EC2 
    el primer servicio q tiene AWS 
    crea las maquinas virtuales on-demand 
    hay una lista con diferentes maquinas y precios x hora 
    (distintas memorias, storage, nucleos)

    ES IMPORTANTE CONOCER DE CLOUD COMPUTING PARA SER BACKEND DEVELOPER 
    LO IDEAL ES METERLE A AWS 
    CERTIFICACIONES: 
    1- CLOUD PRACTICIONER 
        luego se ramifica, lo recomendable es:
    2- DEVELOPER ASOCIATE (y solutions arquitect para armar la arquitectura )
    3- luego vienen los profesionales pero con los primeros va bien

---------------------------------------------------

    AMAZON S3 
    es un servicio de almacenamiento de archivos en la nube
    podemos guardar cualquier cosa(archivos, imagenes lo que sea)
    solo cobran por lo que gastamos en lectura y subida (no cobran por tener el archivo guardado ahi )
    no hay servidor (serverless) 

    AMAZON DYNAMODB
    es la base de datos NoSQL de amazon
    su principal ventaja: 
    muy poca latencia para las consultas 
    tambien es serverless (esta bueno porque por ejemplo si queremos usar una DB SQL tiene q estar montada a un servidor, y este se cobra.
                            en cambio con serverless no se nos cobra nada solo por tener la base en la nube
                            nos cobran solo las unidades de lectura o escritura )

    se basa en que todos los registros tienen una clave (no es como mongoDB)
    tiene la primary key y se puede agregar una segunda KEY 
    - solo se puede consultar por una primary key, eso la hace tan rapida 
        (es otra forma de pensar el diseño de base de datos)
    
    AWS LAMBDA 

    es clave porque le podemos subir una porcion de nuestro codigo 
    y nada mas nos cobran por el tiempo en el que se ejecuto el codigo
    (diferente a levantar una maquina virtual y que nos cobren por hora de uso)
    aca cargamos codigo, configuramos un evento (puede ser un timer cada 3 min, un evento a un endpoint HTTP, una notificacion)
    cuando llega ese evento, LAMBDA cobra vida, ejecuta ese codigo cargado y muere
    solo nos cobran por el tiempo que se invoco ese codigo 
    
    este hay que investigarlo porque sirve para tener servidores baratos 


    AMAZON SIMPLE EMAIL SERVICE 

    servicio que sirve para enviar emails a personas 

    AMAZON SIMPLE NOTIFICATION SERVICE 

    servicio para enviar notificaciones que no son solo emails,
    pueden ser PUSH a celulares,
    (si tenemos una app movil y queremos enviar un push 
    se manda un mensaje a este "topico" (se le dice asi) 
    y reparte a todos los que esten registrados  )
    es un tema de arquitectura publisher suscriber 
    (este patron hace que los suscriptores queden guardados en un servicio 
    y cuando nosotros enviamos una notificacion solo 1 vez hacemos que se reparta a todos)

    esta bueno si hay q mandar mucha info a muchos lugares 
    es mas facil asi q lo mandamos una sola vez y que un servicio como este se encarge de distribuirlo 
    tambien soporta emails, y esta muy bueno para eso 

    SIMPLE QUEUE SERVICE 

    parecido, es un sistema de colas de mensajes 
    si hay que hacer un market , y hacer el endpoint comprar 
    y en el medio tenemos muchos pasos (ver stock, envio, etc)
    para soportar todas estas cargas se usa una:
    comunicacion por colas de mensajes 
    (tambien es un patron de arquitectura )
    tenemos 2 servicios A y B 
    y en vez de hablar directamente 
    A lo manda a una cola de mensajes y cuando se tiene tiempo le llega a B
    asi se garantiza q el mensaje se envíe, y pueda ser procesado bien 

    ---------------------------------------------------------

    navegando en AWS 

    hay 2 formas de crear cosas en AWS 
        - a traves de la consola, de forma grafica 

        - a traves de forma programatica
        (por consola creando los recursos )
        cuando creamos un usuario nuevo nos pide credenciales 
            -programatic access CLAVE (nos da una access key que solo se muestra 1 vez y hay que guardarla )
            -password - AWS managemente console access 

    permisos: 
    AdministratorAccess -> con este el usuario tiene todos los permisos 
    
    si no ponemos nada no vamos a poder hacer nada en AWS ni leer cosas 

    ELASTIC BEANSTALK 
    
    se busca en el buscador de AWS 
    podemos crear todos los recursos por consola 
    tiene ventaja de ser mas intuitivo, pero es dificil de automatizar 
    para esto necesitamos un usuario con acceso programatico 

    hay que configurarle la seguridad porque dice NO SEGURO cuando entras ahi 
    HEROKU hace esto por nosotros y en ese sentido se recomienda 
    (la unica contra de heroku es que la app cuando no le pegamos se duerme,
    algunos hacen un script para que cada cierto tiempo le peguen a la app para que este siempre on
    
    )

    JENKINS

    importante: para automatizar test y hace algunas cosas 
    averiguar.
    tambien averiguar DevOps 


    CODE PIPELINE 

    (se crea un pipeline)
    minuto 1.10 clase AWS explica bien 

    CLOUDWATCH 

    otro servicio clave para guardar LOGS en la nube 

----------------------------------------------------------------------------------

SERVERLESS 

FRAMEWORK que nos ayuda escribir codigo
donde ahi creamos infraestructura con archivos YML 
creamos base de datos 
creamos backend ds3 

solo nos cobran por el uso porque es serverless 

otro framework:
TERRAFORM 
mismo proposito, la idea es escribir codigo
y ahi describir la infraestructura 
si queremos crear una maquina virtual 
creamos un archivo en terraform 

(aca podemos crear lo que quieras, 
maquina virtual, red de internet )
serverless esta mas pensado para las aplicaciones
para arrancar es serverless clave 
pero TERRAFORM es mucho mas completo 

otro framework:
SAM 
(tiene un video clave que explica 

)

-------------------------------------------------

APLICACION TIPICA DE SERVERLESS:
(como arrancar)

ver video en youtube serverless framework complete coding 
gran tutorial de serverless 

npm install -g serverless 

serverless --help 

vamos a la carpeta donde queremos crear el proyecto 

serverless create --help 

--template (arrancamos la aplicacion de lo que querramos)
            (aca va aws-nodejs por ejemplo)

queda algo asi: 

serverless create -t "aws-nodejs" -p "path-donde-creamos-el-servicio"

y nos crea una carpeta con el nombre que le pusimos 
se crea un archivo serverless.yml 
    y aca declaramos nuestras funciones 
la idea es hacerlo con LAMBDA 
se incorpora en el serverless.yml 
la lambda tiene cargado un codigo
se usa un blueprint -> getting started with lambda HTTP 
se usa mediante HTTP que es lo mas comun para que ejecute nuestro codigo con un endpoint 
y nos cobra solo el timepo q ejecutamos ese codigo 

CODIGO: 

en el index.js 
importamos express, 
se inicializa la aplicacion con express()

y se exporta la app con serverless asi:
export const handler = serverless(app)

envuelve la aplicacion de express en serverless 
y tenemos los endpoints que vamos a estar pidiendo aca
a partir de aca es un servidor de express normal 

en los archivos /routes donde estan las rutas get, post 
se importa:

import AWS from 'aws-sdk';

esto es clave para unir NodeJS con AWS 
sirve para crear recursos, leer cosas , hacer todo lo q podemos hacer en la consola AWS pero en esta libreria 
(hay un manual cualquier cosa)

volviendo al YML 
tambien definimos una tabla de base de datos donde vamos a alojar nuestros registros 
en DynamoDB las tablas se manejan por una PRIMARY KEY
entonces tenemos que definir como usarla en -> resources 
(hay un video que explica bien esto buscar )


---------

AWS SKILLBUILDER 
ACA HAY CONTENIDO GRATUITO PARA APRENDER AWS GRATIS y tienen de todo

-------------------

RAILWAY
es la opcion a heroku gratuita con eso hacemos el desafio 
ponemos start new proyect 
deploy from github repo 
elegimos el repo de la app 

cosas a considerar: 
- importante el script start y build al package.json 
- const PORT = process.env.PORT || 8080 

Railway por defecto busca el puerto 8080, no el ENV.PORT como los demas 

- buscar en settings la opcion de generar un dominio gratuito 
    generate domain 
ahi nos da el dominio y nos abre la aplicacion 

cuando hacemos cambios
git add .
git commit 
git push 

y deberia actualizarse


-----------------------------------------------------------------------------

PETICIONES DESDE REACT 

FETCH
Libería nativa de NodeJS que sirve para hacer peticiones
trabaja con promesas, retorna una promesa despues del fetch asi que lleva un .then()

el fetch viene por defecto en GET, sino se aclara con una coma despues del URL 

fetch(http://localhost:8080/api/usuarios)
.then(

)
.catch( 

)

hora 1.01 de la clase consumiendo APIs de react explica ejemplo

-----------------------------

en el modulo de por ejemplo TablaServicioTecnico:
se hace una funcion con el nombre del componente 
dentro se pone un fetch que responde una promesa 
es decir que va un .then y .catch despues de eso 
dentro del then va una funcion con un parámetro (resp) 
y dentro de esa funcion va la resolucion de la promesa en un objeto response 
esta tiene informacion sobre la respuesta de la peticion 
y lleva lo que es la data que devolvio la URL 

como pasar del objeto response a la data de la API:
capturar el parametro (resp) y aplicarle un metodo .json()
el console log retorna una promesa en estado pendiente 
esto significa que el resp.json() retorna una promesa tambien 
esta tengo que trabajarla de forma asincronica 

capturamos la respuesta ed resp.json() sumandole un .then adicional 
hay que return la resp.json()
en el .then adicional va un parametro (data)
y sumarle el otro then donde vamos a capturar la respuesta en formato JSON 
(la data real que envia la API) 


const TablaServicioTecnico () => {

    fetch('http://localhost:8080/users)
        .then( (resp) => {
             return resp.json()
            } )
            .then( (data) => {
                console.log(data)
            } )
        .catch( 

        )


    return ( 

        <div className="container my-5">
            <h2> Users </h2>

        </div>

    )


}

export default TablaServicioTecnico

------------------------------------

LA SINTAXIS CON FETCH SERIA SIEMPRE ASI 

SE CONCATENAN 2(dos) 
.then 
el primer .then retorna una respuesta que retornamos en formato json
el segundo .then recibe la data en JSON como parametro y ya la tiene transformada en la data real 

SE PUEDE SUMARLE ASYNC AWAIT 
pero el objeto .json() hay que capturarlo igual

se puede hacer lo mismo con una sintaxis mas comoda:
(return implicito )

  fetch('http://localhost:8080/users)
    .then((resp) => resp.json())
    .then((data) => {
        console.log(data)
    })

---------------------------

aplicamos el metodo .json porque la info de la api venia en formato json
las API REST trabajan en formato json siempre 

ALGO CLAVE EN EL FETCH 
PORQUE TIENE DEFAULT "GET"
ES PONERLE LA CONFIGURACION CON UNA COMA ,
LUEGO DEL 'URL'

fetch('url', {
    method: 'POST',
    headers: {
        'ApiKey': 'ag1fgafafs-11234-af12'
    },
    body: JSON.stringify({
        id: 2500,
        nombre: 'Mouse Logitech',
        compatibilidad: ['PC', 'PS4', 'PS5' ],
        tipo: [1, 2, 3 ]
    })
})
.then((resp) => resp.json())
.then((data) => console.log(data))

asi creamos un recurso de backend y si sale todo bien 
esta bueno el console.log(data ) que nos manda una copia del resultado 



-------------

Y ASI ESTARIAMOS HACIENDO UNA PETICION GET
PONIENDO EN EL BODY LO QUE NECESITAMOS 
COMO SI FUERA UN POSTMAN 

-----------------

AHORA EL RENDERIZADO 

es clave usar el State de react 
y el useEffect 
para contemplar el estado inicial antes de pasarlo porque nos daria error sino 

y en vez del console.log(data) del segundo fetch 
tenemos que guardar la data en nuestro componente
poniendo en la funcion del segundo .then con el parametro data el estado de lo que pedimos 
setUsers(data) 


const TablaServicioTecnico () => {

    const [users, setUsers] = useState(null) // CLAVE que empiece como null xq cuando hacemos la peticion el estado inicial no está en realidad y da errores 
                                            // 
    useEffect( () => { 

    fetch('http://localhost:8080/users)
        .then( (resp) => resp.json() )
        .then( (data) => {
            setUsers(data)
            } )
        .catch( 

        )

    }, [])

    return ( 

        <div className="container my-5">
                <h2> Users </h2>
                <hr/>
                {
                    user
                    ?
                    <div>
                        <h3> {user.name} </h3>
                        <h3> {user.password} </h3>
                        <img src={user.img} alt={user.name} />

                    </div>
                    :
                    null
                }

        </div>

    )


}

export default TablaServicioTecnico

--------------------------------------------

PARA DARLE FUNCIONALIDAD A LOS BOTONES:

se declara una variable que queremos modificar 
y luego funciones que van a modificar de alguna forma
(eliminando, cambiando un estado )
se llaman 
handleBorrar = () => {

}

handleSumar = () => {

}

y luego en el:

    return (
    <div>

        <button onClick={handleBorrar} className="btn btn-outline-primary"> BORRAR USER </button>

        <button
        onClick={handleSiguiente} 
        className="btn btn-outline-primary"> 
        SIGUIENTE USUARIO 
        </button>

    </div>
)

----------------

ES CLAVE EL ONCLICK={} EN LOS BOTONES 

---------------------------------------------------

cuando modificamos algo hay que modificar el useEffect()
podriamos meter el useEffect completo dentro de cada funcion Borrar o Siguiente 
pero es incomodo

para eso esta el ARRAY DE DEPENDENCIAS que va al final de los useEffect

    useEffect( () => { 

    fetch('http://localhost:8080/users/${id})
        .then( (resp) => resp.json() )
        .then( (data) => {
            setUsers(data)
            } )
        .catch( 

        )

    }, [id])

    aca por ejemplo decimos poniendo el id en el []
    que cada vez que detecte un cambio en el ID
    refresque la informacion 

    LOGICA:
    montamos el componente y ejecutamos el fetch 
    llamamos a la peticion y preparamos la respuesta con los .then
    luego retornamos el XML donde vemos todo reflejado 

    y cada vez que modifiquemos nuestro estado de id 
    que arriba declaramos: 

    const [id, setId] = useState(1) //el parametro significa que arranque en... 1 en este caso 

        ->  se repetiria el efecto (useEffect)
        y actualiza todo incluyendo la renderizacion 
        


----------------------------------------------------------------------------------------------------
https://www.freecodecamp.org/espanol/news/como-crear-una-aplicacion-react-con-un-backend-de-node-la-guia-completa/


INICIAR APLICACION CON REACT 

- npm init -y 

- preparar el index.js y services/server.js 

- instalamos express y todas las dependencias con la base de babel 

- mandamos a puerto 3001 todo lo del servidor 

- antes del server.listen(PORT.....)

- hay que hacer un 

    app.get('/api', (req, res) => {
        res.json({
            msg: "Hola desde el servidor!"
        })
    })

INSTALAMOS BABEL

- npm i @babel/core @babel/cli @babel/node @babel/preset-env -D

- crear archivo .babelrc y adentro 
{
    "presets": ["@babel/preset-env"]
  }

- mandamos los scripts a package.json:

    "build": "babel src --out-dir dist",
    "start": "node ./dist/index.js",
    "dev": "nodemon --exec babel-node ./src/index.js"




-------------------------------------------------------

PARA IMPORTAR IMAGENES EN REACT 
SE PONE EN LA CARPETA LA IMAGEN .SVG:

import logo from './logo.svg'

const App = () => {

    return (
        <div>

            <img src={logo}/>

        </div>
    )

}

------------------------------------------------------

ENVIO DE MENSAJES Y SEGURIDAD 

NODEMAILER 

es un modulo sencillo para aplicaciones node
no tiene dependencias 

enfocada en envio seguro de mails (se pueden incluir htmls o archivos)

usa un protocolo (SMTP) que es por el cual se envian mails 

podemos utilizarla dandole permisos a nuestra cuenta de gmail 

primero trabajamos con una prueba con un mail falso y enviamos a esa casilla 
(esto es bueno para los desarrollos locales )

para los mails "falsos" vamos a utilizar:

ETHEREAL 

es un servidor SMPT falso (como crearse una cuenta dem ail falsa)
el objetivo es probar el funcionamiento del envio de mails 

hay que hacerse una cuenta en la pag de Ethereal y ahi llegan los mails 

luego es usar la liberia de Ethereal ,
y mandar un post a un endpoint 
poniendole dentro de la funcion las variables predeterminadas q tiene Ethereal
como el cuerpo, destinatario, etc 

y para NODEMAILER 
se importa la libreria en un /services/email.js 

y se usa una clase 

esto es en TYPESCRIPT: (en js no se puede asi)
se declaran variables privates que nadie podra ver salvo nosotros 

------------------

import Config from '../config';
import nodemailer from 'nodemailer;


class Email {
    private owner;
    private transporter
}
    constructor() {
        this.owner = {
            name: Config.ETHEREAL_NAME,
            adress: Config.ETHEREAL_EMAIL
        };

        this.transporter = nodemailer.createTransport({
            host: 'smtp.ethereal.email',
            port: 587,
            auth: {
                user: Config.ETHEREAL_EMAIL,
                pass: Config.ETHEREAL_PASSWORD
            },
        });
    }

    async sendEmail(dest: String, subject: String, content: String) {
        const mailOptions = {
            from: this.owner,
            to: dest,
            subject,
            html: content 
        }
    
    const response = await this.transporter.sendMail(mailOptions)


-----------------------------------------------------------------------------------

POINTS PARA TYPESCRIPT:

- por cada librería que tengamos, hay que instalar el @types/... de esa libreria 
- 

xx


--------------------------------------------------------

CLAVE PARA DEPLOYAR APLICACIONES ESTOS SCRIPT: 

    "build": "npm install && babel src --out-dir dist",
    "start": "npm run build && node ./dist/index.js",


------------------------------------------------------------------
------------------------------------------------------------

TERCERA ENTREGA 

1-  SE USA PASSPORT PARA AUTENTICACION DE USUARIOS  
2-  SE USA EL LOGIN QUE GUARDA:
    - EMAIL Y PASSWORD PARA INGRESAR 
    - NOMBRE 
    - DIRECCION 
    - EDAD 
    - TELEFONO 
    - FOTO (tiene q estar guardada en una carpeta public)
    (ver de validar con JSONSchema)
3- ALMACENAR LA CONTRASEÑA ENCRIPTADA EN LA BASE DE DATOS (CRYPTO)
4- FORMULARIO POST DE REGISTRO Y LOGIN
5- LUEGO HAY QUE ACCEDER A UN HOME 
6- EL USUARIO ACCESA CON MAIL Y PASSWORD Y TIENE ACCESO A UN MENU
    (TIPO BARRA DE NAVEGACION, que tenga productos y eso.)
    SUMAR TAMBIEN UN CARRITO 

7- TIENE QUE HABER OPCION PARA DESLOGEARSE DEL SISTEMA 
8- CUANDO SE INCORPORA / REGISTRA UN USUARIO. SE MANDA A NUESTRAS CUENTAS: 
    -MAIL
    -WHATSAPP 
    AVISANDO QUE TAL USUARIO SE REGISTRO 
9- INCORPORAR PRODUCTOS Y UN CARRITO 
    - Y DESDE EL CARRITO TAMBIEN SE ENVIAN DATOS AL BACKEND 
    Y CON ESOS DATOS TAMBIEN SE NOS TIENE Q MANDAR UN MAIL DE QUE COMPRARON ALGO 
    TAMBIEN HAY QUE MANDARLE UN MSJ AL USUARIO CON EL NUMERO QUE DEJO 
    
----------------------------------------------------------------------------------------

REACT 
COMO USAR ROUTER 
(ver curso de Material UI)

para empezar hay que importar en App (para que sea global) 3 librerias claves de React: 

import { BrowseRouter, Routes, Route } from 'react-router-dom';

luego se ponen todos los componentes de la App dentro de un :

<BrowseRouter>



</BrowseRouter>

----------------------------------------------

luego hay que sumar el <Routes> y ponemos todo ahi tambien menos el HEADER, FOOTER, cosas que dejamos fijas . 
queda asi: 



<BrowseRouter>

<Header/>

<Routes>



</Routes>


</BrowseRouter>

---------------------------------------------------

LUEGO VA CADA <Route>
los <Route> reciben 2 elementos como parametros:
1- el path 
2- el element donde va un elemento JSX

    <Route path='/' element='{  }' />

en el element entre corchetes van los componentes que estamos importando por ejemplo <Ingresos/>



-----------------------------------------------------------------------------

DAO - DTO - FACTORY

la DAO es una api que nos permite trabajar con la base de datos 
en vez de trabajar directamente, usamos la api 

FACTORY 

sirve para, en funcion a una variable, que utilice una clase segun lo que necesitemos 
y no tengamos 10 clases distintas que repitan codigo
se puede combinar DAO con FACTORY , y segun la persistencia que necesitemos la factory haga lo suyo 

las clases FACTORY 
se definen con un metodo static (TYPESCRIPT)
por lo general se llama "create"
 y mete un switch - case 
 y cada case x ejemplo "mongo" 
 hace un:
    return new Mongo()




